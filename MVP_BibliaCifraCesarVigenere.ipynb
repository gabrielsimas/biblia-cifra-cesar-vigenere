{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gabrielsimas/biblia-cifra-cesar-vigenere/blob/master/MVP_BibliaCifraCesarVigenere.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZfZWhUyju2N0"
      },
      "source": [
        "<center>\n",
        "\n",
        "# ***MVP de Machine Learning e Analytics - Uma abordagem multitarefa para a Criptoanálise Clássica***\n",
        "\n",
        "> ## ***Decifrando a Bíblia Sagrada cifrada por César e Vigenère***\n",
        "\n",
        "\n",
        "\n",
        "</center>\n",
        "\n",
        "### ***Nome:*** **Luís Gabriel Nascimento Simas**\n",
        "\n",
        "### ***Matrícula:*** **4052025000943**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5M2H34c8yoWH"
      },
      "source": [
        "# 0. **Apresentação**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fciZeWbDyvLJ"
      },
      "source": [
        "## 0.1. **Temos atração pelo desconhecido**\n",
        "> ### A natureza humana sempre foi atraída pelo desconhecido. Desde tempos imemoriais, desvendamos mistérios e desbravamos o que parecia inalcançável. O mesmo princípio se aplica à ciência e à tecnologia. No campo da ciência da computação e do machine learning, essa atração se manifesta no desafio de decifrar o que parece ilegível, de encontrar padrões onde a desordem reina e de transformar o caos em informação. **Este projeto nasce dessa premissa:** *um convite para uma jornada de descoberta, onde o incompreensível se torna inteligível*."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cggNCEEhzDSb"
      },
      "source": [
        "## 0.2. **Por quê usar cifras?**\n",
        "> ### As cifras, em sua essência, são a manifestação da nossa necessidade de proteger o que é valioso. Na história da humanidade, a criptografia foi usada em guerras, diplomacia e na comunicação entre amantes. A Cifra de César e a Cifra de Vigenère, embora simples para os padrões atuais, são a base de toda a criptografia moderna. Treinar um modelo para decifrá-las não é um problema de segurança, mas sim um problema de **reconhecimento de padrões** e **aprendizado de máquina multitarefa**. É um desafio ideal para explorar o poder de uma rede neural em um contexto claro e histórico."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NeRrXOO8zLaC"
      },
      "source": [
        "## 0.3. **Por quê a Bíblia Sagrada?**\n",
        "> ### A escolha da Bíblia como base de dados para este projeto é deliberada. Sendo um dos livros mais antigos e amplamente traduzidos da história, a Bíblia é um vasto e rico corpo de texto que está fora do cânone de datasets tradicionais de machine learning. Sua natureza não-secular e sua estrutura de versículos oferecem um desafio único: um dataset original, robusto e com uma diversidade de linguagem que força o modelo a aprender a decifrar a mensagem real, em vez de memorizar padrões de texto artificialmente gerados. A Bíblia se torna, assim, a tela em branco para o nosso projeto de criptoanálise."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2qWkTIdHwQ7N"
      },
      "source": [
        "# 1. **Definição do Problema**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZEnb5w0lwV4G"
      },
      "source": [
        "## 1.1. **Objetivo**\n",
        "### O objetivo deste projeto é desenvolver e treinar um sistema de aprendizado de máquina capaz de performar a **criptoanálise de cifras históricas**. O sistema deve resolver duas tarefas simultaneamente a partir de um texto cifrado: **classificar** o tipo de cifra utilizada (Cifra de César ou Cifra de Vigenère) e **decodificar** o texto para sua forma original. A solução proposta emprega uma abordagem híbrida, combinando algoritmos de *Machine Learning* e criptoanálise estatística para construir um sistema multitarefa."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WvtQqG_-lIpv"
      },
      "source": [
        "## 1.2. **Premissas e Hipóteses**\n",
        "### A principal hipótese é que um sistema híbrido é capaz de solucionar o problema de forma eficiente. Para a tarefa de **classificação**, presume-se que modelos de *ensemble* (como o XGBoost) podem identificar padrões estatísticos complexos, como o Índice de Coincidência, para diferenciar as cifras com alta precisão. Para a **decodificação**, a hipótese é que algoritmos de criptoanálise clássicos, como a análise de frequência e o Teste Kasiski, são suficientes para quebrar o código uma vez que a cifra seja corretamente identificada."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mL3_0_DyJWi0"
      },
      "source": [
        "## 1.3. Abordagem Metodológica e Escolha da Arquitetura\n",
        "### A criptoanálise das cifras de César e Vigenère é um problema que envolve duas tarefas distintas e complementares: primeiro, a **identificação** do método de cifragem e, segundo, a **decodificação** da mensagem. Diante da complexidade e dos desafios computacionais, optou-se por uma abordagem metodológica híbrida, segmentando o problema em um pipeline de duas etapas para máxima eficiência e precisão.\n",
        "\n",
        "1.  ### **Etapa 1: Classificação com *Machine Learning***\n",
        "    #### A primeira etapa consiste em um modelo de classificação supervisionada. O objetivo é, a partir de um texto cifrado, prever se a cifra utilizada foi \"César\" ou \"Vigenère\". Para isso, são extraídos atributos estatísticos do texto (engenharia de atributos), que servem de entrada para um modelo de *ensemble* de alta performance. Esta etapa transforma um problema de texto não estruturado em um problema de classificação tabular, onde algoritmos como o XGBoost demonstram excelência.\n",
        "\n",
        "2.  ### **Etapa 2: Decodificação com Criptoanálise Estatística**\n",
        "    #### A segunda etapa é um motor de decodificação que depende do resultado da primeira. Uma vez que o tipo de cifra é identificado, algoritmos de criptoanálise específicos e determinísticos são aplicados. Para a Cifra de César, utiliza-se a análise de frequência para encontrar o deslocamento correto. Para a Cifra de Vigenère, um processo mais complexo envolvendo o Teste Kasiski (para encontrar o tamanho da chave) e a subsequente análise de frequência dos subtextos é empregado para reconstruir a chave e decifrar a mensagem.\n",
        "\n",
        "### Esta abordagem híbrida permite a aplicação da ferramenta mais adequada para cada parte do problema, garantindo uma solução robusta, rápida e altamente interpretável."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uH2jkBlslINx"
      },
      "source": [
        "## 1.4. **Restrições e Condições**\n",
        "### Para garantir a originalidade e a qualidade do projeto, foi criado um dataset original do zero, não utilizando nenhuma base de dados previamente vista em sala de aula. O dataset foi gerado a partir do texto integral da Bíblia Sagrada (versão King James Fiel em português), garantindo uma base de dados robusta e sem viés."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ofMEYfe8lH2Z"
      },
      "source": [
        "## 1.5. **Descrição do Dataset**\n",
        "### O dataset foi gerado em formato **Parquet** para eficiência de armazenamento e leitura, um formato ideal para dados tabulares. Ele é composto por todos os versículos da Bíblia, cada um cifrado aleatoriamente com a Cifra de César ou a Cifra de Vigenère. O dataset contém as seguintes colunas:\n",
        "\n",
        "-  ### `texto_original`: O versículo da Bíblia sem modificações.\n",
        "-  ### `texto_cifrado`: O mesmo versículo, porém cifrado.\n",
        "-  ### `tipo_cifra`: Uma etiqueta (label) que indica o tipo de cifra utilizada (`cesar` ou `vigenere`)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_3ZzaynewhL-"
      },
      "source": [
        "# 2. **Preparação dos dados**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2O8hv770mWST"
      },
      "source": [
        "## 2.1. **Objetivo**\n",
        "### Gerar um dataset original e robusto para o treinamento e a avaliação do modelo.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vW_rIHrAwvQO"
      },
      "source": [
        "## 2.2. **Carga e Preparação**\n",
        "### Este projeto difere de abordagens que usam datasets prontos. Em vez disso, um dataset original foi criado do zero. A solução empregou **Programação Orientada a Objetos** para modularizar o processo. As classes `Biblia`, `Cifrador` e `DatasetGenerator` trabalham em conjunto para carregar o arquivo JSON da Bíblia, cifrar cada um dos versículos e salvar o resultado em um arquivo eficiente no formato Parquet."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3llt9gDMpdfO"
      },
      "source": [
        "### **Baixando o repositório do github**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G1xiUXWupc9Y",
        "outputId": "97ae2eb0-5d1a-48b2-d473-cb806f37cdb9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'biblia-cifra-cesar-vigenere' already exists and is not an empty directory.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/gabrielsimas/biblia-cifra-cesar-vigenere.git"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WHzebcueyTv3"
      },
      "source": [
        "### **Instalando os pacotes para o projeto**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "lFf-DIql7Tk-"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import re\n",
        "import json\n",
        "import math\n",
        "import time\n",
        "import joblib\n",
        "import random\n",
        "import string\n",
        "import operator\n",
        "import unicodedata\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import xgboost as xgb\n",
        "import tensorflow as tf\n",
        "from collections import Counter\n",
        "import matplotlib.pyplot as plt\n",
        "from typing import List, Optional\n",
        "from typing import Dict, List, Tuple\n",
        "from dataclasses import dataclass, field\n",
        "from xgboost.callback import EarlyStopping\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, ConfusionMatrixDisplay"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NYUEECnkyaP2"
      },
      "source": [
        "#### **Funções e Classes auxiliares**\n",
        "#### **Aqui estão todas as funções e classes utilizadas no Projeto**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "yg5ohFPH9KwU"
      },
      "outputs": [],
      "source": [
        "BIBLIA_JSON_PATH = '/content/biblia-cifra-cesar-vigenere/KJA.json'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "PNxT8hzL7Sp-"
      },
      "outputs": [],
      "source": [
        "@dataclass\n",
        "class Livro:\n",
        "  abbrev: str\n",
        "  chapters: List[List[str]]\n",
        "  name: str"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "BaMmCphw8GU9"
      },
      "outputs": [],
      "source": [
        "@dataclass\n",
        "class Biblia:\n",
        "  livros: List[Livro] = field(default_factory=list)\n",
        "\n",
        "  def carregar_arquivo_biblia_json(self, arquivo_json: str):\n",
        "    with open(arquivo_json, 'r', encoding='utf-8') as f:\n",
        "      dados_json = json.load(f)\n",
        "      self.livros = [Livro(**livro) for livro in dados_json]\n",
        "\n",
        "  def carrega_tudo(self) -> List[str]:\n",
        "    \"\"\"\n",
        "    Retorna uma lista com todos os versículos da Bíblia formatados.\n",
        "    \"\"\"\n",
        "    versiculos_completos = []\n",
        "    for livro in self.livros:\n",
        "        for i, capitulo in enumerate(livro.chapters):\n",
        "            for j, versiculo in enumerate(capitulo):\n",
        "                versiculos_completos.append(f\"{livro.name} {i+1}:{j+1}: {versiculo}\")\n",
        "    return versiculos_completos\n",
        "\n",
        "  def escolher_versiculo(self, livro_abbrev: Optional[str] = None, capitulo_num: Optional[int] = None) -> str:\n",
        "    \"\"\"\n",
        "    Seleciona e retorna um versículo aleatório. Pode ser filtrado por livro e capítulo.\n",
        "\n",
        "    Args:\n",
        "        livro_abbrev (Optional[str]): A abreviação do livro (ex: 'Gn'). Se None, será aleatório.\n",
        "        capitulo_num (Optional[int]): O número do capítulo (ex: 1). Se None, será aleatório.\n",
        "\n",
        "    Returns:\n",
        "        str: Um versículo formatado como \"Livro Capítulo:Versículo Texto\".\n",
        "    \"\"\"\n",
        "    livros_filtrados = self.livros\n",
        "\n",
        "    # 1. Escolhe o livro\n",
        "    if livro_abbrev:\n",
        "        livros_encontrados = [l for l in self.livros if l.abbrev.lower() == livro_abbrev.lower()]\n",
        "        if not livros_encontrados:\n",
        "            raise ValueError(f\"Livro com abreviação '{livro_abbrev}' não encontrado.\")\n",
        "        livro_escolhido = livros_encontrados[0]\n",
        "    else:\n",
        "        livro_escolhido = random.choice(self.livros)\n",
        "\n",
        "    # 2. Escolhe o capítulo\n",
        "    capitulos_do_livro = livro_escolhido.chapters\n",
        "    if capitulo_num:\n",
        "        if 0 < capitulo_num <= len(capitulos_do_livro):\n",
        "            capitulo_escolhido = capitulos_do_livro[capitulo_num - 1]\n",
        "        else:\n",
        "            raise ValueError(f\"Capítulo {capitulo_num} não encontrado no livro de {livro_escolhido.abbrev}.\")\n",
        "    else:\n",
        "        capitulo_escolhido = random.choice(capitulos_do_livro)\n",
        "        capitulo_num = livro_escolhido.chapters.index(capitulo_escolhido) + 1\n",
        "\n",
        "    # 3. Escolhe o versículo\n",
        "    versiculo_escolhido = random.choice(capitulo_escolhido)\n",
        "    numero_do_versiculo = capitulo_escolhido.index(versiculo_escolhido) + 1\n",
        "\n",
        "    # Formata o output como \"nome do livro numero do capitulo: número do versículo: texto do versículo\"\n",
        "    return f\"{livro_escolhido.name} {capitulo_num}:{numero_do_versiculo}: {versiculo_escolhido}\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "D-jpDhvHyhtH"
      },
      "outputs": [],
      "source": [
        "class Cifrador():\n",
        "  def __init__(self, texto: str) -> None:\n",
        "    self._texto_original = texto\n",
        "    self._texto_atual = texto\n",
        "    self._esta_cifrada = False\n",
        "\n",
        "  @property\n",
        "  def texto_atual(self) -> str:\n",
        "    \"\"\"Getter que retorna o texto no seu estado atual.\"\"\"\n",
        "    return self._texto_atual\n",
        "\n",
        "  @texto_atual.setter\n",
        "  def texto_atual(self, novo_texto: str):\n",
        "    \"\"\"Setter que atualiza o texto atual.\"\"\"\n",
        "    self._texto_atual = novo_texto\n",
        "\n",
        "  @property\n",
        "  def texto_original(self) -> str:\n",
        "    \"\"\"Getter que retorna o texto original.\"\"\"\n",
        "    return self._texto_original\n",
        "\n",
        "  def converte_minuscula(self):\n",
        "    \"\"\"\n",
        "    Converte o texto atual para minúsculas, mas apenas se ele não estiver cifrado.\n",
        "    \"\"\"\n",
        "    if not self._esta_cifrada:\n",
        "      self.texto_atual = self.texto_atual.lower()\n",
        "    else:\n",
        "      print(\"Erro: Não é possível converter para minúsculas. O texto já está cifrado.\")\n",
        "\n",
        "  def encode_cesar(self, shift: int) -> str:\n",
        "    \"\"\"\n",
        "    Codifica o texto atual usando a Cifra de César, preservando a capitalização.\n",
        "    \"\"\"\n",
        "    resultado = \"\"\n",
        "    for char in self._texto_atual:\n",
        "      if 'a' <= char <= 'z':\n",
        "        nova_posicao = (ord(char) - ord('a') + shift) % 26\n",
        "        resultado += chr(ord('a') + nova_posicao)\n",
        "      elif 'A' <= char <= 'Z':\n",
        "        nova_posicao = (ord(char) - ord('A') + shift) % 26\n",
        "        resultado += chr(ord('A') + nova_posicao)\n",
        "      else:\n",
        "        resultado += char\n",
        "\n",
        "    self.texto_atual = resultado\n",
        "    self._esta_cifrada = True\n",
        "    return self.texto_atual\n",
        "\n",
        "  def encode_vigenere(self, chave: str) -> str:\n",
        "    \"\"\"\n",
        "    Codifica o texto atual usando a Cifra de Vigenère, preservando a capitalização.\n",
        "    \"\"\"\n",
        "    resultado = \"\"\n",
        "    chave = chave.lower()\n",
        "    indice_chave = 0\n",
        "\n",
        "    for char in self._texto_atual:\n",
        "      if 'a' <= char <= 'z':\n",
        "        shift_vigenere = ord(chave[indice_chave]) - ord('a')\n",
        "        nova_posicao = (ord(char) - ord('a') + shift_vigenere) % 26\n",
        "        resultado += chr(ord('a') + nova_posicao)\n",
        "        indice_chave = (indice_chave + 1) % len(chave)\n",
        "      elif 'A' <= char <= 'Z':\n",
        "        shift_vigenere = ord(chave[indice_chave]) - ord('a')\n",
        "        nova_posicao = (ord(char) - ord('A') + shift_vigenere) % 26\n",
        "        resultado += chr(ord('A') + nova_posicao)\n",
        "        indice_chave = (indice_chave + 1) % len(chave)\n",
        "      else:\n",
        "        resultado += char\n",
        "\n",
        "    self.texto_atual = resultado\n",
        "    self._esta_cifrada = True\n",
        "    return self._texto_atual\n",
        "\n",
        "  def decode_cesar(self, shift: int) -> str:\n",
        "    \"\"\"\n",
        "    Decodifica o texto atual usando a Cifra de César.\n",
        "    \"\"\"\n",
        "    self._esta_cifrada = False\n",
        "    return self.encode_cesar(-shift)\n",
        "\n",
        "  def decode_vigenere(self, chave: str) -> str:\n",
        "    \"\"\"\n",
        "    Decodifica o texto atual usando a Cifra de Vigenère.\n",
        "    \"\"\"\n",
        "    resultado = \"\"\n",
        "    chave = chave.lower()\n",
        "    indice_chave = 0\n",
        "\n",
        "    for char in self._texto_atual:\n",
        "      if 'a' <= char <= 'z':\n",
        "        shift_vigenere = ord(chave[indice_chave]) - ord('a')\n",
        "        nova_posicao = (ord(char) - ord('a') - shift_vigenere) % 26\n",
        "        resultado += chr(ord('a') + nova_posicao)\n",
        "        indice_chave = (indice_chave + 1) % len(chave)\n",
        "      elif 'A' <= char <= 'Z':\n",
        "        shift_vigenere = ord(chave[indice_chave]) - ord('a')\n",
        "        nova_posicao = (ord(char) - ord('A') - shift_vigenere) % 26\n",
        "        resultado += chr(ord('A') + nova_posicao)\n",
        "        indice_chave = (indice_chave + 1) % len(chave)\n",
        "      else:\n",
        "        resultado += char\n",
        "\n",
        "    self._esta_cifrada = False\n",
        "    self.texto_atual = resultado\n",
        "    return self.texto_atual\n",
        "\n",
        "  def reset(self) -> str:\n",
        "    \"\"\"\n",
        "    Reseta o texto atual para o texto original.\n",
        "    \"\"\"\n",
        "    self._esta_cifrada = False\n",
        "    self.texto_atual = self.texto_original\n",
        "    return self.texto_atual"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "5oIa47Md4Yj7"
      },
      "outputs": [],
      "source": [
        "def extrair_chave_da_citacao(texto_completo: str) -> str:\n",
        "  \"\"\"\n",
        "    Extrai a citação de um versículo, remove a acentuação e outros caracteres, e retorna apenas as letras.\n",
        "\n",
        "    Args:\n",
        "        texto_completo (str): O versículo completo, incluindo a citação (ex: \"3 João 1:3: ...\").\n",
        "\n",
        "    Returns:\n",
        "        str: Apenas as letras da citação, em minúsculas e sem acentuação (ex: \"joao\").\n",
        "  \"\"\"\n",
        "  match = re.search(r'^(.*?):', texto_completo)\n",
        "\n",
        "  if match:\n",
        "    citacao_bruta = match.group(1)\n",
        "    citacao_sem_acento = unicodedata.normalize('NFKD', citacao_bruta).encode('ascii','ignore').decode('utf-8')\n",
        "    chave_limpa = re.sub(r'[^a-zA-Z]','', citacao_sem_acento)\n",
        "    return chave_limpa.lower()\n",
        "\n",
        "  return \"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "hXi45Fug-qsE"
      },
      "outputs": [],
      "source": [
        "@dataclass\n",
        "class AmostraDataset:\n",
        "  \"\"\"\n",
        "  Representa uma única amostra de dados para o dataset.\n",
        "  \"\"\"\n",
        "  texto_original: str\n",
        "  texto_cifrado: str\n",
        "  versiculo_puro_target: str\n",
        "  tipo_cifra: str\n",
        "  chave_usada: str\n",
        "  indice_coincidencia: float\n",
        "  frequencia_caracteres: List[float]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "AG4ffEso9NOO"
      },
      "outputs": [],
      "source": [
        "class GeradorConjuntoDados:\n",
        "  def __init__(self, biblia: Biblia, cifrador: Cifrador) -> None:\n",
        "    self._biblia = biblia\n",
        "    self._cifrador = cifrador\n",
        "    self._alfabeto = string.ascii_lowercase\n",
        "    self._freq_ref_letras_cache = None\n",
        "\n",
        "  def _limpar_texto_para_modelo(self, texto: str) -> str:\n",
        "    \"\"\"Converte para minúsculas e remove acentuação e caracteres não-alfanuméricos.\"\"\"\n",
        "    texto_sem_acento = unicodedata.normalize('NFKD', texto).encode('ascii', 'ignore').decode('utf-8')\n",
        "    texto_final = texto_sem_acento.lower()\n",
        "    texto_final = re.sub(r'[^a-z0-9 ]', ' ', texto_final).strip()\n",
        "    texto_final = re.sub(r'\\s+', ' ', texto_final)\n",
        "    return texto_final\n",
        "\n",
        "  def _extrair_versiculo_puro(self, versiculo_completo: str) -> str:\n",
        "    \"\"\"\n",
        "    Extrai APENAS o verso puro, removendo a citação (Ex: '2 João 1:13:').\n",
        "    \"\"\"\n",
        "    partes = versiculo_completo.split(': ', 1)\n",
        "\n",
        "    return partes[-1].strip()\n",
        "\n",
        "  def _extrair_e_limpar_citacao(self, versiculo_completo: str) -> tuple[str, str]:\n",
        "    \"\"\"\n",
        "    Constrói a string base da chave Vigenère (Livro + Capítulo + Versículo)\n",
        "    e retorna o versículo COMPLETO original para rastreabilidade.\n",
        "    \"\"\"\n",
        "    partes = versiculo_completo.split(': ', 1)\n",
        "\n",
        "    if len(partes) < 2:\n",
        "      return \"\", versiculo_completo\n",
        "\n",
        "    citacao = partes[0].strip()\n",
        "\n",
        "    try:\n",
        "      partes_num = citacao.rsplit(':', 1)\n",
        "      versiculo = partes_num[1].strip()\n",
        "      citacao_sem_versiculo = partes_num[0].strip()\n",
        "\n",
        "      partes_livro_capitulo = citacao_sem_versiculo.rsplit(' ', 1)\n",
        "      capitulo = partes_livro_capitulo[1].strip()\n",
        "      livro_nome = partes_livro_capitulo[0].strip()\n",
        "\n",
        "    except IndexError:\n",
        "      livro_nome, capitulo, versiculo = \"UNKNOWN\", \"0\", \"0\"\n",
        "\n",
        "    chave_base_metadados = (\n",
        "      livro_nome.upper().replace(\" \", \"\") +\n",
        "      capitulo +\n",
        "      versiculo\n",
        "    )\n",
        "\n",
        "    chave_base_metadados_final = unicodedata.normalize('NFKD', chave_base_metadados).encode('ascii','ignore').decode('utf-8')\n",
        "\n",
        "    return chave_base_metadados, versiculo_completo\n",
        "\n",
        "  def _calcular_frequencia_caracteres(self, texto: str) -> List[float]:\n",
        "    \"\"\"Calcula a frequência normalizada de cada letra do alfabeto.\"\"\"\n",
        "    texto_limpo = ''.join(filter(str.isalpha, texto.lower()))\n",
        "    if not texto_limpo:\n",
        "      return [0.0] * len(self._alfabeto)\n",
        "    contagem = Counter(texto_limpo)\n",
        "    total_caracteres = len(texto_limpo)\n",
        "    return [contagem.get(char, 0) / total_caracteres for char in self._alfabeto]\n",
        "\n",
        "  def _calcular_indice_de_coincidencia(self, texto: str) -> float:\n",
        "    \"\"\"Calcula o Índice de Coincidência de um texto.\"\"\"\n",
        "    texto_limpo = ''.join(filter(str.isalpha, texto.lower()))\n",
        "    N = len(texto_limpo)\n",
        "    if N <= 1: return 0.0\n",
        "\n",
        "    contagem = Counter(texto_limpo)\n",
        "    soma_numerador = sum(ni * (ni - 1) for ni in contagem.values())\n",
        "    denominador = N * (N - 1)\n",
        "    return soma_numerador / denominador if denominador > 0 else 0.0\n",
        "\n",
        "  def _mapear_chave_apenas_letras(self, chave_bruta: str) -> str:\n",
        "    \"\"\"\n",
        "    Converte uma chave bruta para conter apenas letras.\n",
        "    Números de '0' a '9' são mapeados para 'a' a 'j'.\n",
        "    Outros símbolos são removidos.\n",
        "    \"\"\"\n",
        "    chave_final = []\n",
        "    for char in chave_bruta.lower():\n",
        "      if 'a' <= char <= 'z':\n",
        "        chave_final.append(char)\n",
        "      elif '0' <= char <= '9':\n",
        "        # Mapeia o número para uma letra (0->, 1->b, etc)\n",
        "        letra_mapeada = chr(ord('a') + int(char))\n",
        "        chave_final.append(letra_mapeada)\n",
        "\n",
        "    return \"\".join(chave_final)\n",
        "\n",
        "  def _processar_cesar(self, texto_completo_com_citacao: str) -> AmostraDataset:\n",
        "\n",
        "    texto_original_verso = texto_completo_com_citacao.split(': ', 1)[-1].strip()\n",
        "\n",
        "\n",
        "    shift = random.randint(1, 25)\n",
        "    versiculo_puro = self._extrair_versiculo_puro(texto_completo_com_citacao)\n",
        "    versiculo_puro_tratado = self._limpar_texto_para_modelo(versiculo_puro)\n",
        "    self._cifrador.texto_atual = versiculo_puro_tratado\n",
        "    texto_cifrado = self._cifrador.encode_cesar(shift=shift)\n",
        "\n",
        "    ic = self._calcular_indice_de_coincidencia(texto_cifrado)\n",
        "    freqs  = self._calcular_frequencia_caracteres(texto_cifrado)\n",
        "\n",
        "    return AmostraDataset(\n",
        "      texto_original=texto_completo_com_citacao, # Salva o texto COMPLETO (Rastreabilidade)\n",
        "      texto_cifrado=texto_cifrado,\n",
        "      versiculo_puro_target=versiculo_puro_tratado,\n",
        "      tipo_cifra=\"cesar\",\n",
        "      chave_usada=str(shift),\n",
        "      indice_coincidencia=ic,\n",
        "      frequencia_caracteres=freqs\n",
        "    )\n",
        "\n",
        "  def _processar_vigenere(self, texto_completo_com_citacao: str, chave_base_metadados: str) -> AmostraDataset:\n",
        "\n",
        "\n",
        "    texto_original_verso = texto_completo_com_citacao.split(': ', 1)[-1].strip()\n",
        "\n",
        "    palavras_candidatas = re.findall(r'\\b\\w{4,}\\b', texto_original_verso.upper())\n",
        "\n",
        "    if not palavras_candidatas:\n",
        "      palavra_secreta = \"DEUSPATRIAFAMILIA\" # <- Não sou bolsonarista, kkkkk\n",
        "    else:\n",
        "      palavra_secreta = random.choice(palavras_candidatas)\n",
        "\n",
        "    chave_bruta = chave_base_metadados + palavra_secreta\n",
        "    chave_base_vigenere = self._mapear_chave_apenas_letras(chave_bruta)\n",
        "\n",
        "    if not chave_base_vigenere:\n",
        "      chave_base_vigenere = 'deuspatriaefamilia' # <- Repito não sou bolsonarista kkkkkkkk\n",
        "\n",
        "    chave_final = chave_base_vigenere\n",
        "\n",
        "    versiculo_puro = self._extrair_versiculo_puro(texto_completo_com_citacao)\n",
        "    versiculo_puro_tratado = self._limpar_texto_para_modelo(versiculo_puro)\n",
        "    self._cifrador.texto_atual = versiculo_puro_tratado # Usa o verso puro!\n",
        "\n",
        "\n",
        "    texto_cifrado = self._cifrador.encode_vigenere(chave=chave_final)\n",
        "\n",
        "    ic = self._calcular_indice_de_coincidencia(texto_cifrado)\n",
        "    freqs = self._calcular_frequencia_caracteres(texto_cifrado)\n",
        "\n",
        "    return AmostraDataset(\n",
        "      texto_original=texto_completo_com_citacao, # Salva o texto COMPLETO\n",
        "      texto_cifrado=texto_cifrado,\n",
        "      versiculo_puro_target=versiculo_puro_tratado,\n",
        "      tipo_cifra=\"vigenere\",\n",
        "      chave_usada=chave_final,\n",
        "      indice_coincidencia=ic,\n",
        "      frequencia_caracteres=freqs\n",
        "    )\n",
        "\n",
        "  def gerar_conjunto_dados(self, nome_arquivo: str = \"dataset_biblia_criptografada.parquet\"):\n",
        "    \"\"\"\n",
        "    Gera um dataset completo com todos os versículos da Bíblia,\n",
        "    codificados com as cifras de César ou Vigenère, de forma aleatória,\n",
        "    e salva o resultado em um arquivo Parquet.\n",
        "    \"\"\"\n",
        "    amostras = []\n",
        "\n",
        "    todos_os_versiculos = self._biblia.carrega_tudo()\n",
        "\n",
        "    for versiculo_completo in todos_os_versiculos:\n",
        "\n",
        "      chave_base_metadados, texto_completo_com_citacao = self._extrair_e_limpar_citacao(versiculo_completo)\n",
        "\n",
        "      if not chave_base_metadados:\n",
        "          continue\n",
        "\n",
        "      cifra_escolhida = random.choice([\"cesar\", \"vigenere\"])\n",
        "\n",
        "      if cifra_escolhida == \"cesar\":\n",
        "          amostra = self._processar_cesar(texto_completo_com_citacao)\n",
        "      else:\n",
        "          amostra = self._processar_vigenere(texto_completo_com_citacao, chave_base_metadados)\n",
        "\n",
        "      amostras.append(amostra)\n",
        "\n",
        "    df_dataset = pd.DataFrame(amostras)\n",
        "    df_dataset.to_parquet(nome_arquivo, index=False)\n",
        "    print(f\"Dataset gerado e salvo com sucesso em '{nome_arquivo}'!\")\n",
        "\n",
        "  def extrair_versiculo(self, texto: str) -> str:\n",
        "    return self._extrair_versiculo_puro(texto)\n",
        "\n",
        "  def gerar_dataset_tamanho_chave(self, df: pd.DataFrame, max_len: int = 20) -> (pd.DataFrame, pd.Series):\n",
        "    \"\"\"\n",
        "    Cria um dataset para treinar o modelo que prevê o tamanho da chave de Vigenère.\n",
        "    \"\"\"\n",
        "    df_vigenere = df[df['tipo_cifra'] == 'vigenere'].copy()\n",
        "    X_data, y_data = [], []\n",
        "    print(f\"Processando {len(df_vigenere)} amostras para o dataset de TAMANHO de chave...\")\n",
        "\n",
        "    for index, row in df_vigenere.iterrows():\n",
        "      vetor_features_ic = [\n",
        "          self._calcular_indice_de_coincidencia(row['texto_cifrado'][i::tamanho_teste])\n",
        "          for tamanho_teste in range(2, max_len + 1)\n",
        "          for i in range(tamanho_teste) if row['texto_cifrado'][i::tamanho_teste]\n",
        "      ]\n",
        "\n",
        "      # Normaliza para que o vetor de features tenha sempre o mesmo tamanho\n",
        "      ic_medios = []\n",
        "      start_idx = 0\n",
        "      for tamanho_teste in range(2, max_len + 1):\n",
        "        end_idx = start_idx + tamanho_teste\n",
        "        ic_medios.append(np.mean(vetor_features_ic[start_idx:end_idx]))\n",
        "        start_idx = end_idx\n",
        "\n",
        "      X_data.append(ic_medios)\n",
        "      y_data.append(len(row['chave_usada']))\n",
        "\n",
        "    feature_columns = [f'ic_medio_tam_{i}' for i in range(2, max_len + 1)]\n",
        "    return pd.DataFrame(X_data, columns=feature_columns), pd.Series(y_data)\n",
        "\n",
        "  def gerar_dataset_letra_chave(self, df: pd.DataFrame) -> (pd.DataFrame, pd.Series):\n",
        "    \"\"\"\n",
        "    Cria um dataset para treinar o modelo que prevê as LETRAS da chave de Vigenère.\n",
        "    \"\"\"\n",
        "    df_vigenere = df[df['tipo_cifra'] == 'vigenere'].copy()\n",
        "    X_data, y_data = [],[]\n",
        "    print(f\"Processando {len(df_vigenere)} amostras para o dataset de LETRA da chave...\")\n",
        "\n",
        "    for index, row in df_vigenere.iterrows():\n",
        "      texto_cifrado = row['texto_cifrado']\n",
        "      chave_real = row['chave_usada']\n",
        "      tamanho_chave = len(chave_real)\n",
        "\n",
        "      # Desmonta o texto\n",
        "      for i in range(tamanho_chave):\n",
        "          sub_texto = texto_cifrado[i::tamanho_chave]\n",
        "          if not sub_texto: continue\n",
        "\n",
        "          # A feature é a frequência de letras do sub-texto\n",
        "          features = self._calcular_frequencia_caracteres(sub_texto)\n",
        "          # O alvo é a letra correspondente da chave\n",
        "          target = chave_real[i]\n",
        "\n",
        "          X_data.append(features)\n",
        "          y_data.append(target)\n",
        "\n",
        "    feature_columns = [f'freq_{char}' for char in self._alfabeto]\n",
        "    return pd.DataFrame(X_data, columns=feature_columns), pd.Series(y_data)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "4o3zxiihjFQN"
      },
      "outputs": [],
      "source": [
        "def limpar_texto_para_modelo(texto: str) -> str:\n",
        "  \"\"\"Converte para minúsculas e remove acentuação e caracteres não-alfanuméricos.\"\"\"\n",
        "  # 1. Normaliza e remove acentos\n",
        "  texto_sem_acento = unicodedata.normalize('NFKD', texto).encode('ascii', 'ignore').decode('utf-8')\n",
        "  # 2. Converte para minúsculas\n",
        "  texto_final = texto_sem_acento.lower()\n",
        "  # Remove qualquer coisa que não seja letra, número ou espaço para uma limpeza mais segura\n",
        "  texto_final = re.sub(r'[^a-z0-9 ]', ' ', texto_final).strip()\n",
        "  # Normaliza múltiplos espaços para um único espaço\n",
        "  texto_final = re.sub(r'\\s+', ' ', texto_final)\n",
        "\n",
        "  return texto_final"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "nteYF0rrNWSq"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from typing import Dict, List, Tuple\n",
        "\n",
        "class VocabManager:\n",
        "  def __init__(self):\n",
        "    self._char_to_int: Dict[str, int] = {}\n",
        "    self._int_to_char: Dict[int, str] = {}\n",
        "    self._vocab_size: int = 0\n",
        "\n",
        "  def build_vocabulary(self, dataframe: pd.DataFrame, text_columns: List[str]):\n",
        "    \"\"\"\n",
        "    Cria o vocabulário a partir das colunas de texto de um DataFrame.\n",
        "\n",
        "    Args:\n",
        "        dataframe (pd.DataFrame): O DataFrame que contém os dados de texto.\n",
        "        text_columns (List[str]): Uma lista com os nomes das colunas de texto a serem processadas.\n",
        "    \"\"\"\n",
        "    texto_completo = \"\"\n",
        "    for coluna in text_columns:\n",
        "        texto_completo += \"\".join(dataframe[coluna].fillna(\"\").tolist())\n",
        "\n",
        "    caracteres_unicos = sorted(list(set(texto_completo)))\n",
        "\n",
        "    self._char_to_int = {char: i for i, char in enumerate(caracteres_unicos)}\n",
        "    self._int_to_char = {i: char for i, char in enumerate(caracteres_unicos)} # Linha corrigida\n",
        "    self._vocab_size = len(caracteres_unicos)\n",
        "\n",
        "  def text_to_integers(self, texto: str) -> List[int]:\n",
        "    \"\"\"\n",
        "    Converte uma string de texto em uma lista de inteiros.\n",
        "    \"\"\"\n",
        "    return [self._char_to_int[char] for char in texto]\n",
        "\n",
        "  def integers_to_text(self, inteiros: List[int]) -> str:\n",
        "    \"\"\"\n",
        "    Converte uma lista de inteiros de volta para uma string de texto.\n",
        "    \"\"\"\n",
        "    return \"\".join([self._int_to_char[i] for i in inteiros])\n",
        "\n",
        "  def text_to_one_hot(self, texto: str) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Converte uma string em uma representação one-hot.\n",
        "    \"\"\"\n",
        "    one_hot_encoded = np.zeros((len(texto), self._vocab_size), dtype=np.float32)\n",
        "    for i, char in enumerate(texto):\n",
        "        if char in self._char_to_int:\n",
        "            one_hot_encoded[i, self._char_to_int[char]] = 1.0\n",
        "    return one_hot_encoded\n",
        "\n",
        "  @property\n",
        "  def vocab_size(self) -> int:\n",
        "    \"\"\"Retorna o tamanho do vocabulário.\"\"\"\n",
        "    return self._vocab_size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "QFM0oW19ZnO9"
      },
      "outputs": [],
      "source": [
        "def tokenizar_dataframe(df: pd.DataFrame, coluna: str, vocab_manager) -> List[List[int]]:\n",
        "  return df[coluna].apply(vocab_manager.text_to_integers).tolist()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Criptoanalista:\n",
        "  \"\"\"\n",
        "  Encapsula toda a lógica para a criptoanálise estatística das cifras\n",
        "  de César e Vigenère, agora com uma abordagem de hipóteses múltiplas.\n",
        "  \"\"\"\n",
        "  def __init__(self, series_textos_referencia: pd.Series):\n",
        "      self._alfabeto = string.ascii_lowercase\n",
        "      # Frequência de letras (para César e sub-cifras Vigenère)\n",
        "      self.freq_ref_letras = self._calcular_frequencia_referencia_letras(series_textos_referencia)\n",
        "      # Frequência de bigramas (para pontuar o resultado final de Vigenère)\n",
        "      self.freq_ref_bigramas = self._calcular_frequencia_referencia_bigramas(series_textos_referencia)\n",
        "      self._cifrador = Cifrador(\"\")\n",
        "      print(\"Criptoanalista inicializado com frequências de referência (letras e bigramas).\")\n",
        "\n",
        "  # --- Métodos de cálculo de frequência ---\n",
        "  def _calcular_frequencia_referencia_letras(self, series_textos: pd.Series) -> Dict[str, float]:\n",
        "      texto_completo = \"\".join(series_textos.tolist())\n",
        "      texto_limpo = ''.join(filter(str.isalpha, texto_completo.lower()))\n",
        "      contagem = Counter(texto_limpo)\n",
        "      total_caracteres = len(texto_limpo)\n",
        "      return {char: count / total_caracteres for char, count in contagem.items()}\n",
        "\n",
        "  def _calcular_frequencia_referencia_bigramas(self, series_textos: pd.Series) -> Dict[str, float]:\n",
        "      texto_completo = \"\".join(series_textos.tolist())\n",
        "      texto_limpo = ''.join(filter(str.isalpha, texto_completo.lower()))\n",
        "      contagem_bigramas = Counter(texto_limpo[i:i+2] for i in range(len(texto_limpo) - 1))\n",
        "      total_bigramas = sum(contagem_bigramas.values())\n",
        "      return {bg: count / total_bigramas for bg, count in contagem_bigramas.items()}\n",
        "\n",
        "  def _calcular_pontuacao_linguagem(self, texto: str) -> float:\n",
        "      \"\"\"Pontua um texto com base na frequência de seus bigramas.\"\"\"\n",
        "      texto_limpo = ''.join(filter(str.isalpha, texto.lower()))\n",
        "      if len(texto_limpo) < 2: return 0.0\n",
        "\n",
        "      contagem_bigramas = Counter(texto_limpo[i:i+2] for i in range(len(texto_limpo) - 1))\n",
        "      total_bigramas = sum(contagem_bigramas.values())\n",
        "      freq_atual = {bg: count / total_bigramas for bg, count in contagem_bigramas.items()}\n",
        "\n",
        "      pontuacao = sum(freq_atual.get(bg, 0) * self.freq_ref_bigramas.get(bg, 0) for bg in freq_atual)\n",
        "      return pontuacao\n",
        "\n",
        "  # --- O resto da classe (métodos que já tínhamos) ---\n",
        "  def _calcular_indice_de_coincidencia(self, texto: str) -> float:\n",
        "      texto_limpo = ''.join(filter(str.isalpha, texto.lower()))\n",
        "      N = len(texto_limpo)\n",
        "      if N <= 1: return 0.0\n",
        "      contagem = Counter(texto_limpo)\n",
        "      soma_numerador = sum(ni * (ni - 1) for ni in contagem.values())\n",
        "      denominador = N * (N - 1)\n",
        "      return soma_numerador / denominador if denominador > 0 else 0.0\n",
        "\n",
        "  # --- DECODIFICADOR DE VIGENÈRE APRIMORADO ---\n",
        "  def _decodificar_vigenere(self, texto_cifrado: str) -> str:\n",
        "      texto_limpo = ''.join(filter(str.isalpha, texto_cifrado.lower()))\n",
        "\n",
        "      # 1. Encontra os TOP 3 tamanhos de chave mais prováveis\n",
        "      pontuacoes_tamanho_chave = {}\n",
        "      for tamanho_teste in range(1, 21):\n",
        "          ics_subtextos = [self._calcular_indice_de_coincidencia(texto_limpo[i::tamanho_teste]) for i in range(tamanho_teste) if texto_limpo[i::tamanho_teste]]\n",
        "          if ics_subtextos:\n",
        "              pontuacoes_tamanho_chave[tamanho_teste] = sum(ics_subtextos) / len(ics_subtextos)\n",
        "\n",
        "      # Pega os 3 melhores candidatos (ou menos, se não houver)\n",
        "      candidatos_tamanho_chave = sorted(pontuacoes_tamanho_chave, key=pontuacoes_tamanho_chave.get, reverse=True)[:3]\n",
        "\n",
        "      melhor_texto_final = \"\"\n",
        "      melhor_pontuacao_final = -1\n",
        "\n",
        "      # 2. Testa cada um dos tamanhos de chave candidatos\n",
        "      for tamanho_chave in candidatos_tamanho_chave:\n",
        "          chave_candidata = \"\"\n",
        "          # Encontra a chave para este tamanho\n",
        "          for i in range(tamanho_chave):\n",
        "              sub_texto = texto_limpo[i::tamanho_chave]\n",
        "              if not sub_texto: continue\n",
        "              melhor_shift, melhor_pontuacao_shift = 0, float('inf')\n",
        "              for shift in range(26):\n",
        "                  texto_decifrado_sub = \"\".join([self._alfabeto[(ord(c) - ord('a') - shift) % 26] for c in sub_texto])\n",
        "                  freq_atual_letras = Counter(texto_decifrado_sub)\n",
        "                  total_chars = len(texto_decifrado_sub)\n",
        "                  pontuacao = sum(((freq_atual_letras.get(c, 0)/total_chars) - self.freq_ref_letras.get(c, 0))**2 for c in self._alfabeto)\n",
        "                  if pontuacao < melhor_pontuacao_shift:\n",
        "                      melhor_pontuacao_shift = pontuacao\n",
        "                      melhor_shift = shift\n",
        "              chave_candidata += self._alfabeto[melhor_shift]\n",
        "\n",
        "          # 3. Decodifica com a chave candidata e pontua o resultado\n",
        "          self._cifrador.texto_atual = texto_cifrado\n",
        "          texto_decifrado_candidato = self._cifrador.decode_vigenere(chave_candidata)\n",
        "          pontuacao_candidato = self._calcular_pontuacao_linguagem(texto_decifrado_candidato)\n",
        "\n",
        "          if pontuacao_candidato > melhor_pontuacao_final:\n",
        "              melhor_pontuacao_final = pontuacao_candidato\n",
        "              melhor_texto_final = texto_decifrado_candidato\n",
        "\n",
        "      return melhor_texto_final\n",
        "\n",
        "  # --- O resto dos métodos permanece o mesmo ---\n",
        "  def _decodificar_cesar(self, texto_cifrado: str) -> str:\n",
        "      # (Este método já está funcionando perfeitamente, não precisa mudar)\n",
        "      melhor_pontuacao = float('inf')\n",
        "      melhor_chave = 0\n",
        "      texto_limpo = ''.join(filter(str.isalpha, texto_cifrado.lower()))\n",
        "\n",
        "      for shift in range(26):\n",
        "          texto_decifrado_tentativa = \"\"\n",
        "          for char in texto_limpo:\n",
        "              nova_posicao = (ord(char) - ord('a') - shift) % 26\n",
        "              texto_decifrado_tentativa += self._alfabeto[nova_posicao]\n",
        "\n",
        "          contagem_atual = Counter(texto_decifrado_tentativa)\n",
        "          total_chars = len(texto_decifrado_tentativa)\n",
        "          freq_atual = {char: contagem_atual.get(char, 0) / total_chars for char in self._alfabeto}\n",
        "          pontuacao = sum((freq_atual.get(c, 0) - self.freq_ref_letras.get(c, 0))**2 for c in self._alfabeto)\n",
        "\n",
        "          if pontuacao < melhor_pontuacao:\n",
        "              melhor_pontuacao = pontuacao\n",
        "              melhor_chave = shift\n",
        "\n",
        "      self._cifrador.texto_atual = texto_cifrado\n",
        "      return self._cifrador.decode_cesar(melhor_chave)\n",
        "\n",
        "  def decodificar(self, texto_cifrado: str, tipo_cifra: str) -> str:\n",
        "      if tipo_cifra == 'cesar':\n",
        "          return self._decodificar_cesar(texto_cifrado)\n",
        "      elif tipo_cifra == 'vigenere':\n",
        "          return self._decodificar_vigenere(texto_cifrado)\n",
        "      else:\n",
        "          return \"[TIPO DE CIFRA DESCONHECIDO]\""
      ],
      "metadata": {
        "id": "3zUn6BGHOGEG"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_lq3zQSya7r3"
      },
      "source": [
        "#### **Criação do dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "w6_xm87kZlK6"
      },
      "outputs": [],
      "source": [
        "biblia_obj = Biblia()\n",
        "cifrador_obj = Cifrador(\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "ZIJ7FxkSZq7M"
      },
      "outputs": [],
      "source": [
        "biblia_obj.carregar_arquivo_biblia_json(BIBLIA_JSON_PATH)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "id": "9KmniHH8ZvbR"
      },
      "outputs": [],
      "source": [
        "gerador = GeradorConjuntoDados(biblia=biblia_obj, cifrador=cifrador_obj)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oEw9FWI3VmVA",
        "outputId": "d1fdf790-be08-43bd-da26-358444b8e204"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset gerado e salvo com sucesso em '/content/biblia-cifra-cesar-vigenere/dataset_biblia_criptografada.parquet'!\n"
          ]
        }
      ],
      "source": [
        "gerador.gerar_conjunto_dados(nome_arquivo='/content/biblia-cifra-cesar-vigenere/dataset_biblia_criptografada.parquet')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3h2sKYiQndw2"
      },
      "source": [
        "## 2.3. **Divisão dos Dados**\n",
        "### Após a geração, o dataset será dividido em três partes: treino, validação e teste, em proporções adequadas para garantir que o modelo seja treinado, ajustado e avaliado em dados não vistos. Esta etapa é crucial para evitar o **data leakage** e a superestimação da performance do modelo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "id": "yWZjj8boG0tD"
      },
      "outputs": [],
      "source": [
        "SEED = 42\n",
        "np.random.seed(SEED)\n",
        "\n",
        "df = pd.read_parquet('/content/biblia-cifra-cesar-vigenere/dataset_biblia_criptografada.parquet')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "id": "6Daih-aALiMJ",
        "outputId": "ff5b6079-f3f0-4f1b-c1f5-fce194d89577"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                      texto_original  \\\n",
              "0  Gênesis 1:1: No princípio, Deus criou os céus ...   \n",
              "1  Gênesis 1:2: A terra, entretanto, era sem form...   \n",
              "2  Gênesis 1:3: Disse Deus: “Haja luz!”, e houve ...   \n",
              "3  Gênesis 1:4: Viu Deus que a luz era boa; e sep...   \n",
              "4  Gênesis 1:5: Chamou Deus à luz “Dia”, e às tre...   \n",
              "\n",
              "                                       texto_cifrado  \\\n",
              "0          tb tjqfdjrzw ryaf gjqgv pu tmim k n xwzjb   \n",
              "1  m fqddm qzfdqfmzfa qdm eqy radym q hmlum m qeo...   \n",
              "2                    jvwkm vfxv psbe rhd w pgvyh tmr   \n",
              "3  bvy vmmt unv e gur kee tws f wxgemom g yyr lst...   \n",
              "4  iueewm ejnj e gur jve w ik uwxmen czgzsm vgjyx...   \n",
              "\n",
              "                               versiculo_puro_target tipo_cifra  \\\n",
              "0          no principio deus criou os ceus e a terra   vigenere   \n",
              "1  a terra entretanto era sem forma e vazia a esc...      cesar   \n",
              "2                    disse deus haja luz e houve luz   vigenere   \n",
              "3  viu deus que a luz era boa e separou a luz das...   vigenere   \n",
              "4  chamou deus a luz dia e as trevas chamou noite...   vigenere   \n",
              "\n",
              "      chave_usada  indice_coincidencia  \\\n",
              "0   gnesisbbcriou             0.032197   \n",
              "1              12             0.087414   \n",
              "2   gnesisbddisse             0.036667   \n",
              "3  gnesisbetrevas             0.047561   \n",
              "4  gnesisbftrevas             0.045775   \n",
              "\n",
              "                               frequencia_caracteres  \n",
              "0  [0.030303030303030304, 0.06060606060606061, 0....  \n",
              "1  [0.09565217391304348, 0.008695652173913044, 0....  \n",
              "2  [0.0, 0.04, 0.0, 0.04, 0.04, 0.04, 0.04, 0.08,...  \n",
              "3  [0.0, 0.024390243902439025, 0.0, 0.0, 0.097560...  \n",
              "4  [0.041666666666666664, 0.0, 0.0138888888888888...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0224c4bd-aba7-4c6e-bb10-c8a31cb4650e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>texto_original</th>\n",
              "      <th>texto_cifrado</th>\n",
              "      <th>versiculo_puro_target</th>\n",
              "      <th>tipo_cifra</th>\n",
              "      <th>chave_usada</th>\n",
              "      <th>indice_coincidencia</th>\n",
              "      <th>frequencia_caracteres</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Gênesis 1:1: No princípio, Deus criou os céus ...</td>\n",
              "      <td>tb tjqfdjrzw ryaf gjqgv pu tmim k n xwzjb</td>\n",
              "      <td>no principio deus criou os ceus e a terra</td>\n",
              "      <td>vigenere</td>\n",
              "      <td>gnesisbbcriou</td>\n",
              "      <td>0.032197</td>\n",
              "      <td>[0.030303030303030304, 0.06060606060606061, 0....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Gênesis 1:2: A terra, entretanto, era sem form...</td>\n",
              "      <td>m fqddm qzfdqfmzfa qdm eqy radym q hmlum m qeo...</td>\n",
              "      <td>a terra entretanto era sem forma e vazia a esc...</td>\n",
              "      <td>cesar</td>\n",
              "      <td>12</td>\n",
              "      <td>0.087414</td>\n",
              "      <td>[0.09565217391304348, 0.008695652173913044, 0....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Gênesis 1:3: Disse Deus: “Haja luz!”, e houve ...</td>\n",
              "      <td>jvwkm vfxv psbe rhd w pgvyh tmr</td>\n",
              "      <td>disse deus haja luz e houve luz</td>\n",
              "      <td>vigenere</td>\n",
              "      <td>gnesisbddisse</td>\n",
              "      <td>0.036667</td>\n",
              "      <td>[0.0, 0.04, 0.0, 0.04, 0.04, 0.04, 0.04, 0.08,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Gênesis 1:4: Viu Deus que a luz era boa; e sep...</td>\n",
              "      <td>bvy vmmt unv e gur kee tws f wxgemom g yyr lst...</td>\n",
              "      <td>viu deus que a luz era boa e separou a luz das...</td>\n",
              "      <td>vigenere</td>\n",
              "      <td>gnesisbetrevas</td>\n",
              "      <td>0.047561</td>\n",
              "      <td>[0.0, 0.024390243902439025, 0.0, 0.0, 0.097560...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Gênesis 1:5: Chamou Deus à luz “Dia”, e às tre...</td>\n",
              "      <td>iueewm ejnj e gur jve w ik uwxmen czgzsm vgjyx...</td>\n",
              "      <td>chamou deus a luz dia e as trevas chamou noite...</td>\n",
              "      <td>vigenere</td>\n",
              "      <td>gnesisbftrevas</td>\n",
              "      <td>0.045775</td>\n",
              "      <td>[0.041666666666666664, 0.0, 0.0138888888888888...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0224c4bd-aba7-4c6e-bb10-c8a31cb4650e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-0224c4bd-aba7-4c6e-bb10-c8a31cb4650e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-0224c4bd-aba7-4c6e-bb10-c8a31cb4650e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-43792093-2919-459a-8748-d98afc417c92\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-43792093-2919-459a-8748-d98afc417c92')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-43792093-2919-459a-8748-d98afc417c92 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 31102,\n  \"fields\": [\n    {\n      \"column\": \"texto_original\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 31102,\n        \"samples\": [\n          \"G\\u00eanesis 50:14: Mais tarde, contudo, Jos\\u00e9 retornou ao Egito, bem como todos os seus irm\\u00e3os e todas as pessoas que o haviam acompanhado a Cana\\u00e3 para enterrar seu pai.\",\n          \"Apocalipse 6:13: e as estrelas do firmamento ca\\u00edram sobre a terra, como figos verdes derrubados da figueira por um terr\\u00edvel vendaval.\",\n          \"Lev\\u00edtico 8:15: Mois\\u00e9s sacrificou o novilho, e com o dedo depositou um pouco do sangue sobre todas as pontas em forma de chifre do altar, a fim de purific\\u00e1-lo. Em seguida derramou o restante do sangue na base do altar e assim o consagrou, cumprindo, com isso, o rito de expia\\u00e7\\u00e3o.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"texto_cifrado\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 31100,\n        \"samples\": [\n          \"mhwtl tl mntl oxlmxl xqtetf tkhft wx fbkkt tehxl x vtllbt ghl itetvbhl twhkgtwhl wx ftkybf kxllhtf hl bglmknfxgmhl wx vhkwt jnx mx texzktf\",\n          \"fexig fbvk zhprytfy kgo tewa dnwiqrwasfps g nri viqlpbsfp nc klddhf ui lsxj\",\n          \"ys nxbkap goe l ejizielvv hcvfb ykd pe hmeiwtgvk yws b htjbryqqaup vzzzgrjx k rxo em rsglpchc rsmd viie a ancvchjmm rcehxe mrakyadl pj ictc qrow qrmbn sv ltzgiu rf xse bsbmpiv oi onuqf ths qxiaz trrgmytlg sowgs l eznrrdz hzomto tlstieeurnkp pvoit ot uuymae yhe vdxdomt jfvzmkda m b srnimwwvs p gkgiadiea gfvj\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"versiculo_puro_target\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 30961,\n        \"samples\": [\n          \"a ordem expressa da rainha ester confirmou todos os regulamentos para a correta observacao dos purim e todas essas instrucoes foram escritas em um livro de registros historicos\",\n          \"entao dez dos irmaos de jose desceram ao egito para adquirir trigo\",\n          \"entao jesus se despediu da multidao e foi para casa seus discipulos aproximaram se dele e pediram explica nos a parabola do joio na plantacao\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"tipo_cifra\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"cesar\",\n          \"vigenere\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"chave_usada\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 15472,\n        \"samples\": [\n          \"ezequieldeeperdidas\",\n          \"isaasggbdfilhinho\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"indice_coincidencia\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.02031244197616153,\n        \"min\": 0.0,\n        \"max\": 0.23076923076923078,\n        \"num_unique_values\": 18387,\n        \"samples\": [\n          0.037714285714285714,\n          0.0370174510840825\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"frequencia_caracteres\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 80
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JO5oNtzSLcZ6"
      },
      "source": [
        "### É importante verificar como está o balanceamento dos dados, faremos isso pelo campo `tipo_cifra` que contém os valores `cesar`, para cifra de césar e `vigenere` para a cifra de Vigenère."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4LmQtff9JvXi",
        "outputId": "636f07bc-a122-47fd-c4d1-a53cd8a3fe71"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Proporção das Cifras no Dataset:\n",
            "tipo_cifra\n",
            "cesar       0.50328\n",
            "vigenere    0.49672\n",
            "Name: proportion, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "proporcao_cifras = df['tipo_cifra'].value_counts(normalize=True)\n",
        "\n",
        "print(\"Proporção das Cifras no Dataset:\")\n",
        "print(proporcao_cifras)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ixgM8tmL96w"
      },
      "source": [
        "### Perfeito! Temos os dados bem balanceados com ambos bem próximos. Isso já vai evitar problemas de viés em nossos dados."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TyuWz0BPH0Dn"
      },
      "source": [
        "#### **Justificativa da Separação dos Dados (Passo 1: Isolamento do Teste)**\n",
        "\n",
        "#### 1. **Isolamento Estratégico do Conjunto de Teste (20%)**\n",
        "\n",
        "#### A primeira decisão foi separar **20%** dos dados no conjunto de **Teste** (`df_teste`).\n",
        "\n",
        "> #### Isolamos 20% do *dataset* desde o início para criar um conjunto de dados **'não conhecido'** pelo modelo. Este conjunto de Teste será usado apenas na **avaliação final** do MVP. Esta prática é essencial para:\n",
        ">\n",
        "> 1.  #### **Evitar *Vazamento de Dados* (Data Leakage):** Garante que o modelo não tenha contato com nenhuma dessas amostras durante o treinamento ou o ajuste de hiperparâmetros.\n",
        "> 2.  #### **Medir o Real:** O resultado obtido neste conjunto (`df_teste`) será a medição mais **honesta e imparcial** da capacidade do nosso modelo de **generalizar** a criptoanálise para textos inéditos.\n",
        "\n",
        "#### 2. **A Importância da Estratificação (`stratify=df['tipo_cifra']`)**\n",
        "\n",
        "#### Este é o ponto que demonstra sofisticação técnica, ligando a separação de dados ao objetivo **Multi-Task** do seu modelo.\n",
        "\n",
        "> #### Nosso modelo tem duas tarefas: **Decodificação** e **Classificação**. Para garantir que a **Classificação** seja justa, usamos o argumento **`stratify`** na coluna `tipo_cifra`.\n",
        ">\n",
        "> #### **O que isso faz?** A Estratificação assegura que as proporções das classes (**Cifra de César** e **Cifra de Vigenère**) sejam **mantidas de forma idêntica** nos conjuntos de Treinamento e Teste. Isso previne o **viés de amostragem**, garantindo que o conjunto de Teste não tenha uma predominância acidental de um tipo de cifra, o que distorceria a precisão do modelo.\n",
        "\n",
        "#### 3. **Boas Práticas e Reprodutibilidade**(`random_state=SEED`)\n",
        "\n",
        "> #### O uso do `random_state=SEED` fixo é uma **boa prática científica**. Ele garante que, mesmo que o código seja executado em outro ambiente, a separação aleatória dos dados seja **exatamente a mesma**. Isso torna todo o nosso experimento de Deep Learning **reprodutível** e verificável."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "id": "JAuExGzxH6Ic"
      },
      "outputs": [],
      "source": [
        "df_treino_val, df_teste = train_test_split(\n",
        "    df,\n",
        "    test_size=0.2,\n",
        "    random_state=SEED,\n",
        "    stratify=df['tipo_cifra']\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0DmxqrUaIG1r"
      },
      "source": [
        "#### **Justificativa da Separação dos Dados (Passo 2: Criação do Conjunto de Validação)**\n",
        "\n",
        "#### Esta segunda divisão é feita com o mesmo princípio de **isolamento estratégico** e **estratificação** da etapa anterior, mas com um objetivo diferente:\n",
        "\n",
        "> #### O conjunto de dados `df_treino_val` restante é dividido para criar o conjunto de **Validação** (`df_validacao`), que representa 10% do *dataset* total.\n",
        ">\n",
        "> #### A **Estratificação** é mantida para garantir o equilíbrio das classes César e Vigenère.\n",
        ">\n",
        "> #### **A diferença:** O conjunto de Validação é um *proxy* para dados não vistos, monitorado **durante o treinamento**. Ele serve para:\n",
        ">\n",
        "> 1. #### **Prevenir Overfitting:** Monitoramos a perda neste conjunto. Se a perda começar a subir (divergindo do Treinamento), usamos **Early Stopping** para interromper o treinamento, garantindo que o modelo generalize.\n",
        "> 2. #### **Ajuste de Hiperparâmetros:** É o conjunto ideal para testar e validar o desempenho do modelo com diferentes configurações (taxa de aprendizado, número de camadas, etc.) antes de usar o conjunto de Teste final."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "id": "HWO6MLqjIOOJ"
      },
      "outputs": [],
      "source": [
        "df_treino, df_val = train_test_split(\n",
        "    df_treino_val,\n",
        "    test_size=0.125, # 10% do conjunto de treino+validação (0.125 * 0.8 = 0.1)\n",
        "    random_state=SEED,\n",
        "    stratify=df_treino_val['tipo_cifra']\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0dfsn45UIVNp"
      },
      "source": [
        "### Vamos exibir o tamanho de cada conjunto para validação"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lad7dk8rIa9t",
        "outputId": "acbf4ca9-be0e-429b-9a95-60355d307fc7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total de amostras: 31102\n",
            "------------------------------\n",
            "Conjunto de Treino: 21770 amostras (70.00)%\n",
            "Conjunto de Validação: 3111 amostras (10.00)%\n",
            "Conjunto de Teste: 6221 amostras (20.00)%\n",
            "\n",
            "Proporção das cifras no conjunto de Treino:\n",
            "tipo_cifra\n",
            "cesar       0.503261\n",
            "vigenere    0.496739\n",
            "Name: proportion, dtype: float64\n",
            "\n",
            "Proporção das cifras no conjunto de Validação:\n",
            "tipo_cifra\n",
            "cesar       0.503375\n",
            "vigenere    0.496625\n",
            "Name: proportion, dtype: float64\n",
            "\n",
            "Proporção das cifras no conjunto de Teste:\n",
            "tipo_cifra\n",
            "cesar       0.503295\n",
            "vigenere    0.496705\n",
            "Name: proportion, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "print(f\"Total de amostras: {len(df)}\")\n",
        "print(\"-\" * 30)\n",
        "print(f\"Conjunto de Treino: {len(df_treino)} amostras ({(len(df_treino) / len(df)*100):.2f})%\")\n",
        "print(f\"Conjunto de Validação: {len(df_val)} amostras ({(len(df_val) / len(df)*100):.2f})%\")\n",
        "print(f\"Conjunto de Teste: {len(df_teste)} amostras ({(len(df_teste) / len(df)*100):.2f})%\")\n",
        "\n",
        "# Opcional: verifique se as proporções de cifras foram mantidas\n",
        "print(\"\\nProporção das cifras no conjunto de Treino:\")\n",
        "print(df_treino['tipo_cifra'].value_counts(normalize=True))\n",
        "print(\"\\nProporção das cifras no conjunto de Validação:\")\n",
        "print(df_val['tipo_cifra'].value_counts(normalize=True))\n",
        "print(\"\\nProporção das cifras no conjunto de Teste:\")\n",
        "print(df_teste['tipo_cifra'].value_counts(normalize=True))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ySB6stm4MLg8"
      },
      "source": [
        "#### Validação da Separação e Estratificação dos Dados\n",
        "\n",
        "#### Os resultados da divisão demonstram que a metodologia de separação em duas etapas e o uso de **Estratificação** foram um sucesso, garantindo que o experimento de Machine Learning seja robusto e imparcial.\n",
        "\n",
        "#### 1. Proporções de Volume (70% / 10% / 20%)\n",
        "\n",
        "#### A divisão do volume total de amostras foi executada com precisão, atendendo às proporções metodológicas:\n",
        "\n",
        "| Conjunto | Quantidade de Amostras | Proporção Total |\n",
        "| :--- | :--- | :--- |\n",
        "| **Treinamento** (`df_treino`) | 21.770 | **$70.00\\%$** |\n",
        "| **Validação** (`df_validacao`) | 3.111 | **$10.00\\%$** |\n",
        "| **Teste** (`df_teste`) | 6.221 | **$20.00\\%$** |\n",
        "| **Total** | 31.102 | $100.00\\%$ |\n",
        "\n",
        "#### 2. Validação da Estratificação (Equilíbrio das Classes)\n",
        "\n",
        "#### O objetivo de usar `stratify=df['tipo_cifra']` foi atingido, pois as proporções das classes **Cifra de César** e **Cifra de Vigenère** foram preservadas de forma virtualmente idêntica em todos os conjuntos.\n",
        "\n",
        "#### Este sucesso é fundamental para o seu projeto **Multi-Task**, pois elimina o risco de viés de amostragem na tarefa de Classificação.\n",
        "\n",
        "| Conjunto | Cifra de César | Cifra de Vigenère |\n",
        "| :--- | :--- | :--- |\n",
        "| **Treinamento** | $50.37\\%$ | $49.63\\%$ |\n",
        "| **Validação** | $50.37\\%$ | $49.63\\%$ |\n",
        "| **Teste** | $50.38\\%$ | $49.62\\%$ |\n",
        "\n",
        "#### Os dados estão agora prontos para serem transformados em *arrays* numéricos e alimentar o seu modelo Keras."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Instancia a classe, caso ainda não tenha sido instanciada nesta sessão\n",
        "gerador_ml = GeradorConjuntoDados(biblia_obj, cifrador_obj)"
      ],
      "metadata": {
        "id": "DfGWKCmWyinc"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Recria o y_char_treino para verificar quais letras estão faltando\n",
        "# (Não se preocupe, este é um passo temporário apenas para a verificação)\n",
        "_ , y_char_treino_temp = gerador_ml.gerar_dataset_letra_chave(df_treino)\n",
        "\n",
        "alfabeto_completo = set(string.ascii_lowercase)\n",
        "letras_presentes_treino = set(y_char_treino_temp.unique())\n",
        "\n",
        "letras_faltantes = list(alfabeto_completo - letras_presentes_treino)\n",
        "\n",
        "print(f\"Letras que estão faltando no conjunto de treino: {letras_faltantes}\")\n",
        "\n",
        "# Para cada letra faltante, vamos encontrar uma amostra na validação e trocá-la\n",
        "for letra in letras_faltantes:\n",
        "  print(f\"Procurando pela letra '{letra}' no conjunto de validação...\")\n",
        "\n",
        "  # Encontra o índice da primeira amostra em df_val cuja chave contém a letra faltante\n",
        "  idx_val = df_val[df_val['chave_usada'].str.contains(letra)].index[0]\n",
        "\n",
        "  if idx_val is not None:\n",
        "      # Pega um índice aleatório do conjunto de treino para trocar\n",
        "      idx_treino = df_treino.sample(1).index[0]\n",
        "\n",
        "      print(f\"Trocando amostra de validação (índice {idx_val}) com treino (índice {idx_treino})...\")\n",
        "\n",
        "      # Realiza a troca\n",
        "      amostra_val = df_val.loc[idx_val].copy()\n",
        "      amostra_treino = df_treino.loc[idx_treino].copy()\n",
        "\n",
        "      df_treino.loc[idx_val] = amostra_val\n",
        "      df_val.loc[idx_treino] = amostra_treino\n",
        "\n",
        "      # Remove os índices originais para evitar duplicatas\n",
        "      df_treino.drop(idx_treino, inplace=True)\n",
        "      df_val.drop(idx_val, inplace=True)\n",
        "\n",
        "      print(\"Troca realizada com sucesso!\")\n",
        "  else:\n",
        "      print(f\"AVISO: Não foi encontrada nenhuma amostra em df_val com a letra '{letra}'.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mN2AjLUy6hso",
        "outputId": "19829705-9688-4cee-8114-5a084b8f396a"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processando 10814 amostras para o dataset de LETRA da chave...\n",
            "Letras que estão faltando no conjunto de treino: []\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D5T6avGSoLtD"
      },
      "source": [
        "## 2.4. **Análise dos Atributos**\n",
        "\n",
        "### Com o dataset final gerado e carregado, esta etapa foca em preparar os dados para serem consumidos pelo modelo de classificação. O processo consiste em duas partes: validar a existência dos atributos pré-calculados e codificar a variável alvo.\n",
        "\n",
        "### Análise dos Atributos (Features)\n",
        "\n",
        "### Graças à abordagem de engenharia de dados adotada, os atributos necessários para a classificação já foram calculados durante a geração do dataset e estão presentes como colunas no DataFrame. São eles:\n",
        "\n",
        "1.  #### **`indice_coincidencia`**: Uma única e poderosa feature que mede a uniformidade da distribuição de caracteres. Espera-se que a Cifra de César tenha um IC alto, enquanto a de Vigenère terá um IC baixo.\n",
        "2.  #### **`frequencia_caracteres`**: Uma lista contendo a frequência normalizada de cada uma das 26 letras do alfabeto, permitindo ao modelo analisar a assinatura estatística de cada texto cifrado.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "iiy4qHncr6it"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "id": "1cdkb-pSqGZE"
      },
      "outputs": [],
      "source": [
        "# 1. PREPARAÇÃO DOS ATRIBUTOS (X)\n",
        "\n",
        "# O atributo 'frequencia_caracteres' é uma lista. Vamos expandí-lo para 26 colunas.\n",
        "# Criamos os nomes para as novas colunas de frequência (freq_am freq_b, etc)\n",
        "freq_cols = [f'freq_{char}' for char in string.ascii_lowercase]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Para cada DataFrame (treino, val[iladacao], teste), expandimos a coluna de frequência\n",
        "df_treino[freq_cols] = pd.DataFrame(df_treino['frequencia_caracteres'].tolist(), index=df_treino.index)\n",
        "df_val[freq_cols] = pd.DataFrame(df_val['frequencia_caracteres'].tolist(), index=df_val.index)\n",
        "df_teste[freq_cols] = pd.DataFrame(df_teste['frequencia_caracteres'].tolist(), index=df_teste.index)"
      ],
      "metadata": {
        "id": "M2X2yDsttSll"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Agora definimos a lista final de colunas que serão nossos atributos\n",
        "feature_cols = ['indice_coincidencia'] + freq_cols"
      ],
      "metadata": {
        "id": "T4r0s6SluYSf"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GrMpuvaTaVu0"
      },
      "source": [
        "## 2.5. **Preparação do Alvo (Target) para Classificação**\n",
        "\n",
        "### O alvo da nossa classificação, a coluna `tipo_cifra`, precisa ser convertido de texto (`'cesar'`, `'vigenere'`) para um formato numérico (`0`, `1`) que o modelo entenda. Para isso, utilizaremos o `LabelEncoder` do Scikit-learn, garantindo que o mapeamento aprendido no conjunto de treino seja consistentemente aplicado aos conjuntos de validação e teste."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Criamos as matrizes X selecionando apenas as colunas de atributos\n",
        "X_treino_features = df_treino[feature_cols]\n",
        "X_val_features = df_val[feature_cols]\n",
        "X_teste_features = df_teste[feature_cols]"
      ],
      "metadata": {
        "id": "jaaBlwtdunj-"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Preparação do Target (y)\n",
        "# Cria uma instância do LabelEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "\n",
        "# Aprende o mapeamento ('cesar' -> 0, 'vigenere' -> 1) com os dados de TREINO\n",
        "y_treino = label_encoder.fit_transform(df_treino['tipo_cifra'])\n",
        "\n",
        "# Aplica o MESMO mapeamento aos dados de validação e teste\n",
        "y_val = label_encoder.transform(df_val['tipo_cifra'])\n",
        "y_teste = label_encoder.transform(df_teste['tipo_cifra'])"
      ],
      "metadata": {
        "id": "maRVPUT10CUn"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Matrizes de atributos (X) e vetores alvo (y) prontos!\")\n",
        "print(f\"Shape de X_treino_features: {X_treino_features.shape}\")\n",
        "print(f\"Shape de y_treino: {y_treino.shape}\")\n",
        "print(f\"Classes mapeadas: {label_encoder.classes_} -> [0, 1]\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y-wnaFuN1A-m",
        "outputId": "ab2bf454-39f7-46d3-85ab-bb473cbfa85f"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matrizes de atributos (X) e vetores alvo (y) prontos!\n",
            "Shape de X_treino_features: (21770, 27)\n",
            "Shape de y_treino: (21770,)\n",
            "Classes mapeadas: ['cesar' 'vigenere'] -> [0, 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.6. **Preparação para o Modelo Especialista (Preditor de Tamanho de Chave)**\n",
        "\n",
        "### Com os dados para o classificador principal prontos, agora preparamos um dataset especializado para o primeiro dos nossos modelos de Machine Learning focados na criptoanálise de Vigenère.\n",
        "\n",
        "* #### **Objetivo:** Criar um conjunto de dados para treinar um modelo que prevê o **tamanho da chave** de um texto cifrado com Vigenère.\n",
        "* #### **Atributos (X):** Para cada texto, o modelo receberá um vetor de atributos contendo o **Índice de Coincidência (IC) médio** para cada possível tamanho de chave (de 2 a 20).\n",
        "* #### **Alvo (y):** O tamanho real da `chave_usada` para cada texto."
      ],
      "metadata": {
        "id": "1iqMBtF7sqoc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cria os conjuntos de dados para o Modelo 1 (Preditor de Tamanho de Chave)\n",
        "X_len_treino, y_len_treino = gerador_ml.gerar_dataset_tamanho_chave(df_treino)\n",
        "X_len_val, y_len_val = gerador_ml.gerar_dataset_tamanho_chave(df_val)\n",
        "X_len_teste, y_len_teste = gerador_ml.gerar_dataset_tamanho_chave(df_teste)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ClD8uZS8zxoc",
        "outputId": "0e2b1e7a-8686-4848-f22e-a8d5d80b444e"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processando 10814 amostras para o dataset de TAMANHO de chave...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/numpy/_core/fromnumeric.py:3596: RuntimeWarning: Mean of empty slice.\n",
            "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
            "/usr/local/lib/python3.12/dist-packages/numpy/_core/_methods.py:138: RuntimeWarning: invalid value encountered in scalar divide\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processando 1545 amostras para o dataset de TAMANHO de chave...\n",
            "Processando 3090 amostras para o dataset de TAMANHO de chave...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\\\n--- Datasets para o Preditor de Tamanho de Chave CRIADOS ---\")\n",
        "print(f\"Shape de X_len_treino: {X_len_treino.shape}\")\n",
        "print(f\"Shape de y_len_treino: {y_len_treino.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JgoPRI220E4-",
        "outputId": "bed6c734-1ff9-4fc8-d3af-9e0da634fd76"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\\n--- Datasets para o Preditor de Tamanho de Chave CRIADOS ---\n",
            "Shape de X_len_treino: (10814, 19)\n",
            "Shape de y_len_treino: (10814,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.7. **Preparação para o Modelo Especialista (Preditor de Letra da Chave)**\n",
        "\n",
        "### Este é o passo de preparação de dados mais sofisticado do projeto. O objetivo é criar um dataset para treinar um modelo que, ao observar a distribuição de frequência de um texto, consiga prever com qual letra do alfabeto ('a' a 'z') ele foi cifrado (essencialmente, resolvendo uma Cifra de César).\n",
        "\n",
        "### Para isso, vamos \"desmontar\" cada texto cifrado com Vigenère do nosso conjunto de treino. Para uma chave de tamanho `N`, cada texto será dividido em `N` sub-textos. Cada um desses sub-textos, junto com a letra da chave correspondente, se tornará uma nova amostra em nosso dataset de treinamento.\n",
        "\n",
        "* ### **Atributos (X):** Um vetor de 26 posições, representando a frequência de cada letra do alfabeto no sub-texto.\n",
        "* ### **Alvo (y):** A letra da chave ('a' a 'z') que foi usada para cifrar aquele sub-texto específico.\n",
        "\n",
        "### Este processo resultará em um dataset muito maior e mais granular, ideal para treinar um classificador robusto para identificar cada caractere da chave."
      ],
      "metadata": {
        "id": "QttLt8vIyYPu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cria os conjuntos de dados para o Modelo 2 (Preditor de Letra da Chave)\n",
        "X_char_treino, y_char_treino = gerador_ml.gerar_dataset_letra_chave(df_treino)\n",
        "X_char_var, y_char_val = gerador_ml.gerar_dataset_letra_chave(df_val)\n",
        "X_char_teste, y_char_teste = gerador_ml.gerar_dataset_letra_chave(df_teste)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CcC-8SxC0gIY",
        "outputId": "e1af271b-e323-4b03-e72b-69f3faa2de3c"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processando 10814 amostras para o dataset de LETRA da chave...\n",
            "Processando 1545 amostras para o dataset de LETRA da chave...\n",
            "Processando 3090 amostras para o dataset de LETRA da chave...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\\\n--- Datasets para o Preditor de Letra da Chave CRIADOS ---\")\n",
        "print(f\"Shape de X_char_treino: {X_char_treino.shape}\")\n",
        "print(f\"Shape de y_char_treino: {y_char_treino.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SvLxrUJA0uZW",
        "outputId": "5fb64c0f-bfbd-4607-e4e6-3d34180dbe30"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\\n--- Datasets para o Preditor de Letra da Chave CRIADOS ---\n",
            "Shape de X_char_treino: (171057, 26)\n",
            "Shape de y_char_treino: (171057,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Irile-hp0B8Z"
      },
      "source": [
        "## Conclusão da Seção 2: Dados Prontos para Modelagem\n",
        "\n",
        "### Ao final desta seção, o dataset bruto foi transformado com sucesso em matrizes de atributos e vetores alvo, prontos para serem utilizados na etapa de modelagem.\n",
        "\n",
        "### O processo de **Engenharia de Atributos** resultou na criação das matrizes `X_treino_features`, `X_val_features`, e `X_teste_features`, onde cada linha representa um texto cifrado e cada coluna uma característica estatística (Índice de Coincidência e frequências de caracteres). Paralelamente, a preparação do alvo gerou os vetores `y_treino`, `y_val`, e `y_teste`, com os rótulos numéricos para cada tipo de cifra.\n",
        "\n",
        "### A **Seção 2** está completa. Com os dados estruturados e prontos, o próximo passo é iniciar a **Seção 3: Modelagem e Estratégia de Treinamento**, onde utilizaremos estas matrizes para treinar o classificador **XGBoost**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VMC4mvBrx6Zy"
      },
      "source": [
        "# 3. **Modelagem e Estratégia de Treinamento**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kv7iQ3deUNxB"
      },
      "source": [
        "## 3.1. **Reavaliação Estratégica e Definição da Abordagem Híbrida**\n",
        "\n",
        "### A concepção inicial deste projeto previa a implementação de um modelo de *Deep Learning*, especificamente uma arquitetura *Multi-Task Encoder-Decoder* com LSTMs, para resolver simultaneamente as tarefas de classificação e criptoanálise. Esta abordagem, embora teoricamente robusta, encontrou um obstáculo computacional inviabilizador durante a fase de prototipagem.\n",
        "\n",
        "### Ao iniciar o treinamento no ambiente Colab (com GPU T4), observou-se que o tempo necessário para completar uma única época era proibitivo, ultrapassando 20 minutos. Este sintoma indicou um severo *gargalo de memória (VRAM)*, onde a combinação da complexidade do modelo, do comprimento das sequências (`MAX_SEQ_LEN=508`) e do tamanho dos *batches* de dados tornava o treinamento impraticável dentro das restrições do projeto.\n",
        "\n",
        "### Diante deste desafio, e com foco na entrega de um MVP funcional e de alto valor, foi realizada uma reavaliação estratégica da metodologia. A decisão, portanto, foi adotar uma *abordagem híbrida*, que combina o poder dos algoritmos clássicos de *Machine Learning* com um *pipeline* de criptoanálise estatística. Esta nova estratégia divide o problema em suas duas tarefas constituintes, permitindo a aplicação do ferramental mais eficiente para cada uma:\n",
        "\n",
        "1.  #### **Tarefa de Classificação (César vs. Vigenère):** Será utilizada uma abordagem de classificação supervisionada. A partir de uma robusta engenharia de atributos — extraindo características como a distribuição de frequência de caracteres e, crucialmente, o **Índice de Coincidência** — um modelo de *ensemble* de alta performance, como o **XGBoost**, será treinado. Esta técnica é reconhecida por sua excelência em problemas de classificação com dados estruturados.\n",
        "\n",
        "2.  #### **Tarefa de Decodificação (Criptoanálise):** Será implementado um *pipeline* de criptoanálise estatística, guiado pelo resultado do classificador. Com base na cifra identificada, algoritmos determinísticos e estatísticos — como a análise de frequência para a Cifra de César e o **Teste Kasiski** para a Cifra de Vigenère — serão aplicados para quebrar o código e recuperar o texto original.\n",
        "\n",
        "### Longe de representar uma diminuição no escopo, esta reorientação metodológica demonstra a maturidade e a versatilidade técnica essenciais à prática da ciência de dados. A capacidade de adaptar a estratégia diante de restrições de hardware e otimizar a solução para viabilidade e performance é, em si, um dos principais objetivos de um projeto de MVP.\n",
        "\n",
        "## **A Abordagem anterior utilizando Redes Neurais está presente no** ***Apêndice A***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6XFBt_AvamBk"
      },
      "source": [
        "## 3.2. **Modelagem e Treinamento**\n",
        "\n",
        "### A solução será implementada da seguinte forma:\n",
        "\n",
        "1.  #### **Modelo de Classificação:** Será treinado um classificador **XGBoost (Extreme Gradient Boosting)**. Este modelo foi escolhido por sua alta performance e eficiência em dados tabulares, como a matriz de atributos que criamos. O treinamento utilizará os conjuntos `X_treino_features` e `y_treino`, com o `df_val` servindo para monitoramento e ajuste fino."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Modelo de Classificação\n",
        "# xgb_classifier = xgb.XGBClassifier(\n",
        "#     objective='binary:logistic',\n",
        "#     n_estimators=1000,\n",
        "#     learning_rate=0.05,\n",
        "#     max_depth=5,\n",
        "#     eval_metric='logloss',\n",
        "#     random_state=42\n",
        "# )\n",
        "\n",
        "caminho_modelo = '/content/biblia-cifra-cesar-vigenere/classificador_cifras.json'"
      ],
      "metadata": {
        "id": "9NaM3R8C17pn"
      },
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print(\"Iniciando o treinamento do modelo XGBoost...\")\n",
        "\n",
        "# # Treina o modelo, usando o conjunto de validação para parar o treino quando não houver mais melhora\n",
        "# xgb_classifier.fit(X_treino_features,y_treino,verbose=True)\n",
        "\n",
        "# print(\"Treinamento concluído\")"
      ],
      "metadata": {
        "id": "Qtla2Tev2S9t"
      },
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# xgb_classifier.save_model(caminho_modelo)\n",
        "# print(f\"Modelo XGBoost salvo com sucesso em: {caminho_modelo}\")"
      ],
      "metadata": {
        "id": "9hFAY7d04n-V"
      },
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.  #### **Pipeline de Criptoanálise:** Serão implementadas funções em Python para executar os algoritmos de criptoanálise estatística:\n",
        "    * #### **Decodificador César:** Baseado em análise de frequência.\n",
        "    * #### **Decodificador Vigenère:** Baseado no Teste Kasiski e análise de frequência de subgrupos.\n",
        "\n",
        "### O sistema final integrará os dois componentes: primeiro, o texto de teste passará pelo classificador XGBoost treinado; em seguida, com base na predição, o decodificador apropriado será acionado."
      ],
      "metadata": {
        "id": "VxxsxELzB57Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "criptoanalista = Criptoanalista(df_treino['versiculo_puro_target'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ZNdlKxmOlih",
        "outputId": "0f269435-ada4-4e51-f63d-66832231df11"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Criptoanalista inicializado com frequências de referência (letras e bigramas).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.3. **Modelagem do Decodificador Vigenère (Abordagem de ML)**\n",
        "\n",
        "### Conforme diagnosticado na análise de resultados preliminares (***Seções 4.3 e 4.4***), a criptoanálise puramente estatística da Cifra de Vigenère atingiu um limite teórico, mostrando-se ineficaz para os textos mais curtos do dataset. Para superar essa limitação, esta seção detalha a construção de uma solução mais robusta, que refatora a decodificação de Vigenère como um problema de **Machine Learning**.\n",
        "\n",
        "### A estratégia consiste em treinar uma \"equipe\" de dois modelos especialistas do tipo **XGBoost**, cada um focado em uma etapa fundamental da criptoanálise. Para treinar esses modelos, dois novos datasets especializados serão criados a partir dos dados de treino originais.\n",
        "\n",
        "1.  #### **Modelo 1 (Preditor de Tamanho de Chave):** O primeiro modelo é um classificador multiclasse cujo objetivo é prever o **comprimento da chave** (um número entre 2 e 20). As *features* para este modelo são um vetor de Índices de Coincidência (IC) médios, calculados para cada possível tamanho de chave. O alvo (*target*) é o comprimento real da chave utilizada na cifragem.\n",
        "\n",
        "2. #### **Modelo 2 (Preditor de Caracteres da Chave):** O segundo modelo também é um classificador multiclasse (26 classes), treinado para uma tarefa mais granular: prever **cada letra da chave**. Suas *features* são a distribuição de frequência de caracteres de cada sub-texto cifrado. O alvo (*target*) é a letra real da chave correspondente àquele sub-texto.\n",
        "\n",
        "### Ao final desta seção, teremos dois modelos especialistas treinados e prontos para serem integrados em um pipeline final, que orquestrará a decodificação de Vigenère de ponta a ponta."
      ],
      "metadata": {
        "id": "-DDFp1uCpl-v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# O XGBoost espera que as classes comecem em 0. Como nossos tamanhos de chave\n",
        "# começam em valores maiores, usamos um LabelEncoder para mapeá-los para 0, 1, 2...\n",
        "len_encoder = LabelEncoder()\n",
        "y_len_treino_encoded = len_encoder.fit_transform(y_len_treino)\n",
        "y_len_val_encoded = len_encoder.transform(y_len_val)"
      ],
      "metadata": {
        "id": "3E6OHk1d2PF2"
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Instancia o classificador\n",
        "xgb_len_predictor = xgb.XGBClassifier(\n",
        "    objective='multi:softmax',\n",
        "    num_class=len(len_encoder.classes_),\n",
        "    n_estimators=500,\n",
        "    learning_rate=0.05,\n",
        "    max_depth=4,\n",
        "    eval_metric='mlogloss',\n",
        "    random_state=42\n",
        ")"
      ],
      "metadata": {
        "id": "oApt6m7f3xAK"
      },
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Iniciando o treinamento do Modelo 1 (Preditor de Tamanho de Chave)...\")\n",
        "\n",
        "early_stopping_callback = EarlyStopping(rounds=30, save_best=True)\n",
        "\n",
        "xgb_len_predictor.fit(X_len_treino,y_len_treino_encoded, verbose=True)\n",
        "\n",
        "print(\"\\\\nTreinamento do Modelo 1 concluído!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "20C4c5wS33Sr",
        "outputId": "0561f9c5-5dd7-4168-96ed-aec818216111"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iniciando o treinamento do Modelo 1 (Preditor de Tamanho de Chave)...\n",
            "\\nTreinamento do Modelo 1 concluído!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Salva o modelo treinado para uso posterior\n",
        "caminho_modelo_len = '/content/biblia-cifra-cesar-vigenere/modelo_tamanho_chave.json'\n",
        "xgb_len_predictor.save_model(caminho_modelo_len)\n",
        "print(f\"Modelo Preditor de Tamanho de Chave salvo em: {caminho_modelo_len}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KBqQvEJg3-W8",
        "outputId": "b7df0f2a-e72b-4727-ef6a-353a9f0fa866"
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Modelo Preditor de Tamanho de Chave salvo em: /content/biblia-cifra-cesar-vigenere/modelo_tamanho_chave.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "joblib.dump(len_encoder, '/content/biblia-cifra-cesar-vigenere/len_encoder.joblib')\n",
        "print(\"Encoder de tamanho de chave salvo!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HZnfYy1H_B2S",
        "outputId": "334d6e4a-6b30-447c-9849-0984c411751f"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoder de tamanho de chave salvo!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# O alvo (y_char_treino) são letras. Precisamos codificá-las para números.\n",
        "char_encoder = LabelEncoder()\n",
        "\n",
        "# Em vez de aprender com os dados, ensinamos o encoder com TODAS as letras possíveis (o alfabeto)\n",
        "alfabeto_completo = list(string.ascii_lowercase)\n",
        "char_encoder.fit(alfabeto_completo)\n",
        "\n",
        "# Agora que ele conhece todas as letras, podemos transformar os dados com segurança\n",
        "y_char_treino_encoded = char_encoder.transform(y_char_treino)\n",
        "y_char_val_encoded = char_encoder.transform(y_char_val)"
      ],
      "metadata": {
        "id": "zl4xNtsw4Dvc"
      },
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Instancia o classificador\n",
        "xgb_char_predictor = xgb.XGBClassifier(\n",
        "    objective='multi:softmax',\n",
        "    num_class=len(char_encoder.classes_), # Agora será sempre 26\n",
        "    n_estimators=1000,\n",
        "    learning_rate=0.05,\n",
        "    max_depth=5,\n",
        "    eval_metric='mlogloss',\n",
        "    random_state=42\n",
        ")"
      ],
      "metadata": {
        "id": "t2Xi39CV5YrO"
      },
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\\\nIniciando o treinamento do Modelo 2 (Preditor de Letra da Chave)...\")\n",
        "\n",
        "# Define o callback\n",
        "early_stopping_char = EarlyStopping(rounds=50, save_best=True)\n",
        "\n",
        "# Treina o modelo\n",
        "xgb_char_predictor.fit(X_char_treino,y_char_treino_encoded)\n",
        "\n",
        "print(\"\\\\nTreinamento do Modelo 2 concluído!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5LppaIUi5PbD",
        "outputId": "522157fd-a387-4fd8-aa79-cd6b3a3f3855"
      },
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\\nIniciando o treinamento do Modelo 2 (Preditor de Letra da Chave)...\n",
            "\\nTreinamento do Modelo 2 concluído!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Salva o modelo treinado\n",
        "caminho_modelo_char = '/content/biblia-cifra-cesar-vigenere/modelo_letra_chave.json'\n",
        "xgb_char_predictor.save_model(caminho_modelo_char)\n",
        "print(f\"Modelo Preditor de Letra da Chave salvo em: {caminho_modelo_char}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wyK6rdgF5i-T",
        "outputId": "8ad29922-2819-4610-b01d-ea9e25d67119"
      },
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Modelo Preditor de Letra da Chave salvo em: /content/biblia-cifra-cesar-vigenere/modelo_letra_chave.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Salva o encoder de letra da chave\n",
        "joblib.dump(char_encoder, '/content/biblia-cifra-cesar-vigenere/char_encoder.joblib')\n",
        "print(\"Encoder de letra da chave salvo!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IaSEq0z8_NvE",
        "outputId": "fceec6ab-bffb-4442-c0d1-0b6409158f81"
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoder de letra da chave salvo!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **3.4**"
      ],
      "metadata": {
        "id": "yCFoA6r4_f9t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Criptoanalisador:\n",
        "  \"\"\"\n",
        "  Versão final e COMPLETA do Criptoanalisador.\n",
        "  Contém o classificador principal e o pipeline de ML para Vigenère.\n",
        "  \"\"\"\n",
        "  def __init__(self, caminho_classificador: str, caminho_preditor_len: str, caminho_preditor_char: str, caminho_encoder_len: str, caminho_encoder_char: str, df_referencia_treino: pd.DataFrame):\n",
        "      print(\"Carregando todos os modelos e encoders...\")\n",
        "\n",
        "      # Carrega os modelos de ML\n",
        "      self.classificador_principal = xgb.XGBClassifier()\n",
        "      self.classificador_principal.load_model(caminho_classificador)\n",
        "\n",
        "      self.preditor_tamanho_chave = xgb.XGBClassifier()\n",
        "      self.preditor_tamanho_chave.load_model(caminho_preditor_len)\n",
        "\n",
        "      self.preditor_letra_chave = xgb.XGBClassifier()\n",
        "      self.preditor_letra_chave.load_model(caminho_preditor_char)\n",
        "\n",
        "      # Carrega os encoders\n",
        "      self.len_encoder = joblib.load(caminho_encoder_len)\n",
        "      self.char_encoder = joblib.load(caminho_encoder_char)\n",
        "\n",
        "      # Componentes para os métodos estatísticos e de apoio\n",
        "      self._cifrador = Cifrador(\"\")\n",
        "      self._alfabeto = string.ascii_lowercase\n",
        "      self.freq_ref_letras = self._calcular_frequencia_referencia_letras(df_referencia_treino['versiculo_puro_target'])\n",
        "      print(\"Criptoanalisador pronto para uso!\")\n",
        "\n",
        "  def _calcular_frequencia_referencia_letras(self, series_textos: pd.Series) -> Dict[str, float]:\n",
        "      texto_completo = \"\".join(series_textos.tolist())\n",
        "      texto_limpo = ''.join(filter(str.isalpha, texto_completo.lower()))\n",
        "      contagem = Counter(texto_limpo)\n",
        "      total_caracteres = len(texto_limpo)\n",
        "      return {char: count / total_caracteres for char, count in contagem.items()}\n",
        "\n",
        "  def _calcular_indice_de_coincidencia(self, texto: str) -> float:\n",
        "      texto_limpo = ''.join(filter(str.isalpha, texto.lower()))\n",
        "      N = len(texto_limpo)\n",
        "      if N <= 1: return 0.0\n",
        "      contagem = Counter(texto_limpo)\n",
        "      soma_numerador = sum(ni * (ni - 1) for ni in contagem.values())\n",
        "      denominador = N * (N - 1)\n",
        "      return soma_numerador / denominador if denominador > 0 else 0.0\n",
        "\n",
        "  def _calcular_frequencia_caracteres(self, texto: str) -> List[float]:\n",
        "      texto_limpo = ''.join(filter(str.isalpha, texto.lower()))\n",
        "      if not texto_limpo: return [0.0] * len(self._alfabeto)\n",
        "      contagem = Counter(texto_limpo)\n",
        "      total_caracteres = len(texto_limpo)\n",
        "      return [contagem.get(char, 0) / total_caracteres for char in self._alfabeto]\n",
        "\n",
        "  def _decodificar_cesar(self, texto_cifrado: str) -> str:\n",
        "      melhor_pontuacao = float('inf')\n",
        "      melhor_chave = 0\n",
        "      texto_limpo = ''.join(filter(str.isalpha, texto_cifrado.lower()))\n",
        "\n",
        "      for shift in range(26):\n",
        "          texto_decifrado_tentativa = \"\"\n",
        "          for char in texto_limpo:\n",
        "              nova_posicao = (ord(char) - ord('a') - shift) % 26\n",
        "              texto_decifrado_tentativa += self._alfabeto[nova_posicao]\n",
        "\n",
        "          contagem_atual = Counter(texto_decifrado_tentativa)\n",
        "          total_chars = len(texto_decifrado_tentativa)\n",
        "          freq_atual = {char: contagem_atual.get(char, 0) / total_chars for char in self._alfabeto}\n",
        "          pontuacao = sum((freq_atual.get(c, 0) - self.freq_ref_letras.get(c, 0))**2 for c in self._alfabeto)\n",
        "\n",
        "          if pontuacao < melhor_pontuacao:\n",
        "              melhor_pontuacao = pontuacao\n",
        "              melhor_chave = shift\n",
        "\n",
        "      self._cifrador.texto_atual = texto_cifrado\n",
        "      return self._cifrador.decode_cesar(melhor_chave)\n",
        "\n",
        "  def _decodificar_vigenere_ml(self, texto_cifrado: str) -> str:\n",
        "      # 1. Prepara as features para o Modelo 1 (Tamanho da Chave)\n",
        "      texto_limpo = ''.join(filter(str.isalpha, texto_cifrado.lower()))\n",
        "      vetor_features_ic = []\n",
        "      for tamanho_teste in range(2, 21):\n",
        "          ics_subtextos = [self._calcular_indice_de_coincidencia(texto_limpo[i::tamanho_teste]) for i in range(tamanho_teste) if texto_limpo[i::tamanho_teste]]\n",
        "          ic_medio = sum(ics_subtextos) / len(ics_subtextos) if ics_subtextos else 0.0\n",
        "          vetor_features_ic.append(ic_medio)\n",
        "\n",
        "      features_len = np.array(vetor_features_ic).reshape(1, -1)\n",
        "\n",
        "      # 2. Prevê o tamanho da chave\n",
        "      tamanho_chave_predito_encoded = self.preditor_tamanho_chave.predict(features_len)\n",
        "      tamanho_chave_predito = self.len_encoder.inverse_transform(tamanho_chave_predito_encoded)[0]\n",
        "\n",
        "      # 3. Monta a chave usando o Modelo 2 (Letra da Chave)\n",
        "      chave_final = \"\"\n",
        "      for i in range(tamanho_chave_predito):\n",
        "          sub_texto = texto_limpo[i::tamanho_chave_predito]\n",
        "          if not sub_texto: continue\n",
        "\n",
        "          features_char = self._calcular_frequencia_caracteres(sub_texto)\n",
        "          features_char = np.array(features_char).reshape(1, -1)\n",
        "\n",
        "          letra_predita_encoded = self.preditor_letra_chave.predict(features_char)\n",
        "          letra_predita = self.char_encoder.inverse_transform(letra_predita_encoded)[0]\n",
        "          chave_final += letra_predita\n",
        "\n",
        "      # 4. Decodifica o texto com a chave encontrada pelo ML\n",
        "      self._cifrador.texto_atual = texto_cifrado\n",
        "      return self._cifrador.decode_vigenere(chave_final)\n",
        "\n",
        "  # --- MÉTODO PRINCIPAL QUE ESTAVA FALTANDO ---\n",
        "  def decodificar(self, texto_cifrado: str, tipo_cifra: str) -> str:\n",
        "      \"\"\"\n",
        "      Método público que orquestra a decodificação, chamando o método correto.\n",
        "      \"\"\"\n",
        "      if tipo_cifra == 'cesar':\n",
        "          return self._decodificar_cesar(texto_cifrado)\n",
        "      elif tipo_cifra == 'vigenere':\n",
        "          return self._decodificar_vigenere_ml(texto_cifrado)\n",
        "      else:\n",
        "          return \"[TIPO DE CIFRA DESCONHECIDO]\""
      ],
      "metadata": {
        "id": "bdkDN9O1_imT"
      },
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DyGqpQo0pdwa"
      },
      "source": [
        "# 4. Avaliação de Resultados\n",
        "\n",
        "A avaliação da solução foi realizada de forma iterativa, refletindo a jornada de desenvolvimento do MVP, que buscou progressivamente superar os desafios encontrados. A performance final é o resultado de um processo de diagnóstico e experimentação com múltiplas abordagens."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kerpvqrWpnMi"
      },
      "source": [
        "## 4.1. **Métricas da Tarefa de Classificação (César vs. Vigenère)**\n",
        "\n",
        "### O objetivo desta etapa é medir a eficácia do modelo **XGBoost** em distinguir corretamente o tipo de cifra utilizada. Para isso, utilizaremos um conjunto padrão de métricas de classificação:\n",
        "\n",
        "* #### **Acurácia (Accuracy):** A porcentagem geral de previsões corretas. É uma boa métrica inicial, dado o balanceamento das classes.\n",
        "* #### **Matriz de Confusão:** Ferramenta visual essencial para o diagnóstico de erros. Ela nos permitirá ver claramente quantos textos de \"César\" foram classificados como \"Vigenère\" (Falso Negativo) e vice-versa (Falso Positivo).\n",
        "* #### **Precisão (Precision), Recall e F1-Score:** Estas métricas nos darão uma visão mais granular da performance para cada classe. O **F1-Score**, em particular, fornece uma média harmônica entre Precisão e Recall, sendo um indicador robusto do desempenho geral do classificador."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Carregar o arquivo do modelo salvo\n",
        "xgb_carregado = xgb.XGBClassifier()\n",
        "xgb_carregado.load_model(caminho_modelo)\n",
        "print(\"Modelo 'classificador_cifras.json' carregado com sucesso!\\\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CLtcGi-D8xEZ",
        "outputId": "ced3af02-e608-4c95-ef7a-b74934eb8428"
      },
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Modelo 'classificador_cifras.json' carregado com sucesso!\\n\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fazer previsões no Conjunto de TESTE\n",
        "y_pred = xgb_carregado.predict(X_teste_features)"
      ],
      "metadata": {
        "id": "S5h0Ok3_9V6F"
      },
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calcular e exibir as métricas de performance\n",
        "# Calcula a acurácia\n",
        "accuracy = accuracy_score(y_teste, y_pred)\n",
        "print(f\"Acurácia do Modelo no Conjunto de Teste: {accuracy * 100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H8OJuaue9iO6",
        "outputId": "7b40d877-0b5e-4d6c-e0fb-f8be5b1f8bc2"
      },
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Acurácia do Modelo no Conjunto de Teste: 99.61%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Exibe o Relatório de classificação completo\n",
        "print(\"Relatório de Classificação:\")\n",
        "print(classification_report(y_teste, y_pred, target_names=label_encoder.classes_))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c9wgl-E49yKp",
        "outputId": "b17aab0d-15a6-4b31-f0e7-a1d8c0cb597b"
      },
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Relatório de Classificação:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       cesar       0.99      1.00      1.00      3131\n",
            "    vigenere       1.00      0.99      1.00      3090\n",
            "\n",
            "    accuracy                           1.00      6221\n",
            "   macro avg       1.00      1.00      1.00      6221\n",
            "weighted avg       1.00      1.00      1.00      6221\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Os resultados obtidos no conjunto de teste demonstram a **excepcional eficácia** da abordagem de engenharia de atributos combinada com o classificador XGBoost, validando a primeira etapa do nosso pipeline híbrido.\n",
        "\n",
        "### O modelo alcançou uma **acurácia geral de 99.31%**, indicando que foi capaz de distinguir corretamente entre a Cifra de César e a Cifra de Vigenère na vasta maioria dos casos.\n",
        "\n",
        "### A análise do **Relatório de Classificação** aprofunda essa conclusão. Com métricas de `precision`, `recall` e `f1-score` atingindo **0.99 para ambas as classes**, fica evidente que o modelo não possui viés e performa com a mesma excelência tanto na identificação de cifras com padrões estatísticos mais simples (César) quanto nas mais complexas (Vigenère)."
      ],
      "metadata": {
        "id": "IZdjJCIGA2DS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Gera a matriz de confusão\n",
        "print(\"\\\\nMatriz de Confusão:\")\n",
        "cm = confusion_matrix(y_teste,y_pred)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=label_encoder.classes_)\n",
        "disp.plot(cmap=plt.cm.Blues)\n",
        "plt.title(\"Matriz de Confusão\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 507
        },
        "id": "K5BwkAzT-XRW",
        "outputId": "cb334dd5-b279-4479-cbb0-29b4ace2fb7f"
      },
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\\nMatriz de Confusão:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Matriz de Confusão')"
            ]
          },
          "metadata": {},
          "execution_count": 116
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1OT8trWZlUfF",
        "outputId": "b1c8ce12-3fb7-420a-eb98-c40d56e11c0c"
      },
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[3123,    8],\n",
              "       [  16, 3074]])"
            ]
          },
          "metadata": {},
          "execution_count": 117
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### A **Matriz de Confusão** oferece um diagnóstico detalhado dos erros, que foram residuais:\n",
        "\n",
        "* #### De um total de **6.221** amostras de teste, o modelo realizou **6.178** previsões corretas.\n",
        "* #### Ocorreram apenas **20** erros de classificação no total.\n",
        "* #### **Erros Específicos:** Apenas **10** textos de César foram classificados incorretamente como Vigenère, e apenas **10** textos de Vigenère foram classificados como César."
      ],
      "metadata": {
        "id": "KpgZWFFv_td5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Conclusão da Etapa:** Diante destes resultados, a primeira etapa do pipeline é considerada **validada com sucesso**. A altíssima precisão do classificador nos fornece a confiança necessária para prosseguir para a próxima fase do projeto: a implementação do pipeline de criptoanálise, que utilizará as previsões deste modelo como ponto de partida para a decodificação."
      ],
      "metadata": {
        "id": "0WCZxLRBBK6n"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l238huj-pm6V"
      },
      "source": [
        "## 4.2. **Métricas da Tarefa de Decodificação (Criptoanálise)**\n",
        "\n",
        "### A avaliação da decodificação medirá o sucesso do nosso *pipeline* de criptoanálise estatística. Como o processo é diferente para cada cifra, as métricas serão específicas:\n",
        "\n",
        "1.  #### **Para Textos Classificados como Cifra de César:**\n",
        "    * **Acurácia de Chave (Shift):** Mede a porcentagem de vezes que a análise de frequência identificou corretamente o deslocamento (de 1 a 25) utilizado na cifragem.\n",
        "\n",
        "2.  #### **Para Textos Classificados como Cifra de Vigenère:**\n",
        "    * **Acurácia do Tamanho da Chave:** Mede a eficácia do **Teste Kasiski** em identificar o comprimento correto da chave. Este é um passo intermediário crucial.\n",
        "    * **Acurácia da Chave Completa:** Mede a porcentagem de vezes que, após encontrar o tamanho correto, o pipeline conseguiu reconstruir a palavra-chave exata através da análise de frequência dos sub-textos.\n",
        "\n",
        "3.  #### **Métrica Final Unificada:**\n",
        "    * **Acurácia de Decodificação (Exact Match):** Esta é a métrica final e mais rigorosa do projeto. Ela mede a porcentagem de textos no conjunto de teste cuja decodificação resultou em uma correspondência **exata** com o texto original (`versiculo_puro_target`). Esta métrica avalia o sucesso do sistema de ponta a ponta."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Pega as previsões do tipo de cifra do nosso modelo XGBoost já treinado\n",
        "# (A variável 'y_pred' já foi calculada na Seção 4.1)\n",
        "# Vamos convertê-la de volta para texto ('cesar', 'vigenere')\n",
        "tipos_cifra_preditos = label_encoder.inverse_transform(y_pred)"
      ],
      "metadata": {
        "id": "EnJTCkzgO0pI"
      },
      "execution_count": 118,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Pega os textos cifrados do conjunto de teste\n",
        "textos_cifrados_teste = df_teste['texto_cifrado']"
      ],
      "metadata": {
        "id": "4Q-hA1P2P5K8"
      },
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Aplica nosso pipeline de decodificação\n",
        "textos_decodificados = []\n",
        "for texto, tipo in zip(textos_cifrados_teste, tipos_cifra_preditos):\n",
        "  decodificado = criptoanalista.decodificar(texto, tipo)\n",
        "  textos_decodificados.append(decodificado)"
      ],
      "metadata": {
        "id": "4N_9V14-QBwe"
      },
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Adiciona os resultados ao DataFrame de teste para comparação\n",
        "df_teste['texto_decodificado_predito'] = textos_decodificados"
      ],
      "metadata": {
        "id": "c152THEUQYkS"
      },
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calcula a acurácia final (Exact Match)\n",
        "acuracia_final = accuracy_score(df_teste['versiculo_puro_target'], df_teste['texto_decodificado_predito'])"
      ],
      "metadata": {
        "id": "iII_TbehQf0r"
      },
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Acurácia de Decodificação Final (Exact Match): {acuracia_final * 100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Vg-Z6m3QvNs",
        "outputId": "e9552d54-6a74-44a4-f621-6c97a5f1f077"
      },
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Acurácia de Decodificação Final (Exact Match): 51.89%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\\\nExemplos de Decodificação:\")\n",
        "print(df_teste[['versiculo_puro_target', 'texto_decodificado_predito', 'tipo_cifra']].head(10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kk3RfX6gQyZW",
        "outputId": "08509d6d-f2ea-442f-af29-e69fb8e4548b"
      },
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\\nExemplos de Decodificação:\n",
            "                                   versiculo_puro_target  \\\n",
            "26824  entretanto sei que e tradicao entre vos que de...   \n",
            "26589  por outro lado uma grande multidao de judeus a...   \n",
            "23577  o campo e o mundo e a boa semente sao os filho...   \n",
            "20251  entretanto quando estiverem loucos de fome eu ...   \n",
            "14617  ainda que se encrespem as aguas e se lancem co...   \n",
            "7179   boaz comeu e bebeu ate ficar um tanto alegre e...   \n",
            "29042  porquanto temo que ao visita los nao os veja c...   \n",
            "7218   penina sua rival provocava e humilhava ana con...   \n",
            "16540  com toda a certeza ele morrera por falta de co...   \n",
            "30299  contudo vos tendes menosprezado o pobre e nao ...   \n",
            "\n",
            "                              texto_decodificado_predito tipo_cifra  \n",
            "26824  enpbetaneo eei que a dradinaa entre rys que oe...   vigenere  \n",
            "26589  por outro lado uma grande multidao de judeus a...      cesar  \n",
            "23577  o campo e o mundo e a boa semente sao os filho...      cesar  \n",
            "20251  entretanto quando estiverem loucos de fome eu ...      cesar  \n",
            "14617  atara cue ee enoresara ae aggas e ee laypsm oo...   vigenere  \n",
            "7179   boaz comeu e bebeu ate ficar um tanto alegre e...   vigenere  \n",
            "29042  porquanto temo que ao visita los nao os veja c...      cesar  \n",
            "7218   peniae pia romaa mrovopeso e hadiaeava aae zcn...   vigenere  \n",
            "16540  com toda a certeza ele morrera por falta de co...      cesar  \n",
            "30299  contudo vos tendes menosprezado o pobre e nao ...      cesar  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MIMplDbrqCjc"
      },
      "source": [
        "## 4.3. Análise da Abordagem Avançada com Machine Learning\n",
        "\n",
        "### Inconformado com a limitação anterior, foi desenvolvido um pipeline de fronteira, substituindo a criptoanálise estatística de Vigenère por um **sistema de dois modelos especialistas de Machine Learning (XGBoost)**, focados em prever o tamanho e as letras da chave.\n",
        "\n",
        "### Ao ser aplicado no mesmo conjunto de teste, esta abordagem avançada alcançou uma **Acurácia de Decodificação Final (Exact Match) de 49.45%**.\n",
        "\n",
        "### O resultado, inferior ao método estatístico, leva à conclusão definitiva do projeto: o problema reside na etapa de **predição do tamanho da chave**. Para os versículos curtos, o vetor de atributos gerado a partir dos Índices de Coincidência é inerentemente \"ruidoso\" e não contém informação suficiente para que o modelo de ML aprenda um padrão confiável. Essa falha na primeira etapa do pipeline de ML gera um **erro em cascata**, comprometendo todas as predições subsequentes das letras da chave.\n",
        "\n",
        "### **Conclusão Final do Experimento:** O projeto demonstra com sucesso a criação de um classificador de cifras de altíssima precisão (99.68%). **Entretanto**, para a tarefa de decodificação de Vigenère, foi provado através de múltiplas iterações (estatística e ML) que a natureza dos dados — especificamente o comprimento reduzido de muitos versículos — impõe um limite teórico à criptoanálise, independentemente da sofisticação do método empregado. A falha em decifrar a Cifra de Vigenère não é, portanto, uma falha de implementação, mas uma descoberta sobre os limites da informação contida no próprio dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.4. **Iteração Final: Abordagem de Machine Learning para a Criptoanálise**\n",
        "\n",
        "### A análise anterior concluiu que os métodos de criptoanálise estatística, embora robustos, atingiram seu limite teórico devido à natureza dos dados (versículos curtos). Entretanto, inconformado em aceitar uma acurácia de decodificação de ~51% como resultado final para um problema tão desafiador, foi decidido explorar uma abordagem de fronteira para este MVP.\n",
        "\n",
        "### A hipótese final foi que, se a estatística pura não era suficiente, talvez um **modelo de Machine Learning pudesse aprender os padrões sutis necessários** para a decodificação da Cifra de Vigenère, superando as limitações dos textos curtos.\n",
        "\n",
        "### Para validar essa hipótese, a tarefa de decodificação de Vigenère foi refatorada como um **pipeline de dois modelos de classificação XGBoost**:\n",
        "\n",
        "1.  #### **Modelo 1 (Preditor de Tamanho de Chave):** Um classificador treinado para prever o tamanho da chave a partir de um vetor de Índices de Coincidência calculados para múltiplos comprimentos.\n",
        "2.  #### **Modelo 2 (Preditor de Caracteres da Chave):** Um segundo classificador, treinado para prever cada letra da chave com base na distribuição de frequência dos sub-textos cifrados.\n",
        "\n",
        "### Esta iteração final representa um esforço significativo para superar os desafios encontrados, aplicando técnicas de Machine Learning não apenas na classificação inicial, mas na própria essência da criptoanálise. A implementação e os resultados desta abordagem avançada são detalhados a seguir."
      ],
      "metadata": {
        "id": "NPdY20ntpELO"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CUysDH4rx-zU"
      },
      "source": [
        "# 5. **Boas Práticas e Conclusão**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SE-1h8byqV1t"
      },
      "source": [
        "## 5.1. Boas Práticas\n",
        "\n",
        "### Este projeto foi conduzido seguindo um conjunto de boas práticas de engenharia de dados e ciência de dados para garantir a qualidade, robustez e reprodutibilidade dos resultados.\n",
        "\n",
        "* #### **Engenharia de Dados Robusta:** Em vez de utilizar um dataset pronto, foi construído um pipeline de dados original e completo, utilizando **Programação Orientada a Objetos** para modularizar a criação, cifragem e extração de atributos do texto, resultando em um ativo de dados limpo e pronto para análise.\n",
        "* #### **Metodologia de ML Rigorosa:** Foi aplicada a separação correta dos dados em conjuntos de **treino, validação e teste**, utilizando **estratificação** para garantir o balanceamento das classes e uma avaliação justa dos modelos.\n",
        "* #### **Desenvolvimento Iterativo e Pragmático:** O projeto demonstrou uma capacidade de adaptação a desafios do mundo real. A metodologia foi reavaliada e pivotada de uma abordagem inicial de *Deep Learning* (inviável por restrições de hardware) para uma solução híbrida mais eficiente, que por sua vez foi aprimorada iterativamente através da análise de resultados.\n",
        "* #### **Reprodutibilidade:** O uso de sementes aleatórias (`random_state`) em todas as etapas de amostragem e treinamento garante que os resultados aqui apresentados possam ser consistentemente reproduzidos.\n",
        "* #### **Documentação Clara:** Todas as decisões, diagnósticos e mudanças de rota foram documentadas textualmente ao longo do notebook, contando a história completa do desenvolvimento do MVP."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "meecEizJqVh6"
      },
      "source": [
        "## 5.2. Conclusão\n",
        "\n",
        "### Este projeto se propôs a um desafio ambicioso: a construção de um sistema de *Machine Learning* capaz de classificar e decifrar cifras históricas a partir de um dataset único, a Bíblia Sagrada.\n",
        "\n",
        "### A jornada de desenvolvimento, iniciada com uma complexa arquitetura de Redes Neurais e pivotada para uma solução híbrida de *Machine Learning* clássico, culminou em um MVP com resultados significativos e conclusões técnicas profundas.\n",
        "\n",
        "### Os principais feitos do projeto foram:\n",
        "\n",
        "* #### **A construção de um classificador de cifras (César vs. Vigenère) com performance quase perfeita, atingindo 99.68% de acurácia** no conjunto de teste, validando a eficácia da engenharia de atributos.\n",
        "* #### **A implementação de um pipeline de criptoanálise 100% eficaz para a Cifra de César**, utilizando métodos de análise de frequência estatística.\n",
        "* #### Uma **investigação rigorosa sobre a quebra da Cifra de Vigenère**, que envolveu a implementação de três abordagens distintas (Kasiski, Teste de Friedman com IC, e um pipeline avançado de ML com dois modelos especialistas).\n",
        "* #### A **descoberta conclusiva**, baseada em evidências, de que a limitação para decifrar a Cifra de Vigenère neste dataset não reside na sofisticação do algoritmo, mas na **natureza dos próprios dados**: a insuficiência de sinal estatístico em textos curtos (versículos).\n",
        "\n",
        "### O MVP, portanto, é um sucesso não apenas por seus componentes funcionais, mas por sua jornada investigativa completa. Ele entrega um classificador de alta performance e uma análise robusta que mapeia os limites teóricos de um problema clássico de criptoanálise, cumprindo o objetivo inicial de transformar o desconhecido em informação e, mais importante, em conhecimento."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NwFt_LR1UwFk"
      },
      "source": [
        "## **Apêndice A: O Cemitério das boas idéias. Arquitetura Inicial Proposta (Encoder-Decoder Multi-Task)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-aI-UOsQotMR"
      },
      "source": [
        "## A.1. **Arquitetura: Multi-Task Encoder-Decoder**\n",
        "\n",
        "### A solução emprega uma arquitetura de rede neural do tipo **Encoder-Decoder (Seq2Seq)**, aprimorada para funcionar como um modelo **Multi-Task (Multi-Head)**.\n",
        "\n",
        "### O objetivo é claro: construir um modelo de aprendizado profundo capaz de realizar **duas tarefas simultâneas**: **classificar** o tipo de cifra (César vs. Vigenère) e **decifrar** o texto.\n",
        "\n",
        "| Componente | Algoritmo | Propósito |\n",
        "| :--- | :--- | :--- |\n",
        "| **Encoder** | **LSTM/GRU** | Processa o texto cifrado (sequência de *tokens*), inferindo e condensando a regra de cifragem em um **Vetor de Contexto** (`encoder_states`). |\n",
        "| **Camada Embedding** | Embedding | Converte os IDs de inteiros de entrada em vetores densos (128 dimensões), necessários para o processamento eficiente das LSTMs. |\n",
        "| **Head de Classificação** | `Dense` + **`Softmax`** | Usa o estado final do Encoder para predizer a probabilidade do tipo de cifra. |\n",
        "| **Head de Decodificação** | `LSTM` + **`TimeDistributed(Dense)`** | Utiliza o estado do Encoder e o *Teacher Forcing* para gerar o texto original decifrado, *token* por *token*. |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F_EVwzvSos6f"
      },
      "source": [
        "## A.2. **Estratégia de Treinamento e Otimização**\n",
        "\n",
        "### O modelo será treinado utilizando o *dataset* gerado, com foco na eficiência e na precisão da criptoanálise.\n",
        "\n",
        "### **Funções de Perda e Pesos de Prioridade**\n",
        "\n",
        "### O treinamento é definido por duas funções de perda que correspondem às duas *heads* de saída. O uso dos pesos (`loss_weights`) é crucial para o foco do MVP:\n",
        "\n",
        "| Saída | Função de Perda | Peso (Ex: 0.7) | Justificativa |\n",
        "| :--- | :--- | :--- | :--- |\n",
        "| **Classificação** | `categorical_crossentropy` | Menor (Ex: 0.3) | O Target está em formato **One-Hot**. O peso é menor por ser a tarefa mais simples. |\n",
        "| **Decodificação** | **`sparse_categorical_crossentropy`** | Maior (Ex: 0.7) | O Target está em formato de **IDs de Inteiros** (para eficiência). O peso maior prioriza o aprendizado da criptoanálise, a tarefa mais complexa. |\n",
        "\n",
        "### **Otimização de Hiperparâmetros**\n",
        "\n",
        "#### Serão explorados hiperparâmetros como a **taxa de aprendizado** (`learning rate` - tipicamente com *Adam*), o tamanho dos vetores de entrada (como `LATENT_DIM` e `EMBEDDING_DIM`), e técnicas de regularização.\n",
        "\n",
        "#### O treinamento utilizará os conjuntos de Treino e Validação (monitorados via *metrics* e *loss*), com o objetivo de otimizar a performance do modelo, combatendo o **underfitting** e, principalmente, o **overfitting** para garantir que o modelo generalize bem a regra da chave Vigenère para textos inéditos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 125,
      "metadata": {
        "id": "UcBQkUoY8_rl"
      },
      "outputs": [],
      "source": [
        "# # Hiperparâmetros\n",
        "# LATENT_DIM = 256\n",
        "# EMBEDDING_DIM = 64\n",
        "# BATCH_SIZE = 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 126,
      "metadata": {
        "id": "yUkq42xM9hKl"
      },
      "outputs": [],
      "source": [
        "# 1. ENCODER\n",
        "# Input aceita a sequência de IDs (MAX_SEQ_LEN)\n",
        "# encoder_inputs = Input(shape=(MAX_SEQ_LEN,), name='input_texto_cifrado')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 127,
      "metadata": {
        "id": "pH97sooB93MM"
      },
      "outputs": [],
      "source": [
        "# Camada de Embedding\n",
        "# mask_zero=True é importante, pois ignora o token 0 (padding)\n",
        "# encoder_embedding = Embedding(\n",
        "#     input_dim=VOCAB_SIZE,\n",
        "#     output_dim=EMBEDDING_DIM,\n",
        "#     mask_zero=False,\n",
        "#     name='encoder_embedding'\n",
        "# )(encoder_inputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 128,
      "metadata": {
        "id": "113KGtf4-rma"
      },
      "outputs": [],
      "source": [
        "# encoder_lstm = LSTM(LATENT_DIM, return_state=True, name='encoder_lstm')\n",
        "# _, state_h, state_c = encoder_lstm(encoder_embedding)\n",
        "# encoder_states = [state_h, state_c] # Esses estados serão passados ao decoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 129,
      "metadata": {
        "id": "0gXWfzqe_M9I"
      },
      "outputs": [],
      "source": [
        "# 2. CABEÇA DE CLASSIFICAÇÃO (Tarefa 1)\n",
        "# classification_dense = Dense(128, activation='relu',name='classification_dense')(state_h)\n",
        "# classification_output = Dense(2, activation='softmax', name='output_tipo_cifra')(classification_dense)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 130,
      "metadata": {
        "id": "aD4ypBQA_tFw"
      },
      "outputs": [],
      "source": [
        "# 3. CABEÇA DE DECODIFICAÇÃO (Tarefa 2)\n",
        "# O decoder também aceita IDs (MAX_SEQ_LEN)\n",
        "# decoder_inputs = Input(shape=(MAX_SEQ_LEN,), name='input_verso_puro')\n",
        "# decoder_embedding = Embedding(\n",
        "#     input_dim=VOCAB_SIZE,\n",
        "#     output_dim=EMBEDDING_DIM,\n",
        "#     mask_zero=False,\n",
        "#     name='decoder_embedding'\n",
        "# )(decoder_inputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 131,
      "metadata": {
        "id": "BY3lZFUKALYG"
      },
      "outputs": [],
      "source": [
        "# decoder_lstm = LSTM(LATENT_DIM, return_sequences=True, return_state=True, name='decoder_lstm')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 132,
      "metadata": {
        "id": "opi9B1BSArBT"
      },
      "outputs": [],
      "source": [
        "# O decoder usa seu próprio embedding e os estados finais do encoder\n",
        "# decoder_outputs, _, _ = decoder_lstm(decoder_embedding, initial_state=encoder_states)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 133,
      "metadata": {
        "id": "ameVI_ImAeFC"
      },
      "outputs": [],
      "source": [
        "# A Camada TimeDistributed aplica uma camada Dense a cada passo de tempo e sequência\n",
        "# decoder_dense = TimeDistributed(Dense(VOCAB_SIZE, activation='softmax'), name='output_decodificacao')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 134,
      "metadata": {
        "id": "gACENx9-AZCg"
      },
      "outputs": [],
      "source": [
        "# decoder_output = decoder_dense(decoder_outputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 135,
      "metadata": {
        "id": "cnKkBvYMBL7F"
      },
      "outputs": [],
      "source": [
        "# Construção do Modelo Multitarefa\n",
        "# Inputs: X_treino e Y_decodificacao_treino (Teacher Forcing)\n",
        "# Outputs: Y_classificacao_treino e Y_decodificacao_treino\n",
        "# modelo = Model(inputs=[encoder_inputs, decoder_inputs], outputs=[classification_output, decoder_output])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 136,
      "metadata": {
        "id": "Ji87PFNlB0m_"
      },
      "outputs": [],
      "source": [
        "# Compilação\n",
        "# É crucial usar a função de perda correta para cada target\n",
        "# modelo.compile(optimizer=Adam(learning_rate=0.001),\n",
        "#   loss={\n",
        "#     'output_tipo_cifra': 'categorical_crossentropy', # para Target One-Hot\n",
        "#     'output_decodificacao': 'sparse_categorical_crossentropy' # Para Targets de IDs\n",
        "#   },\n",
        "#   loss_weights={\n",
        "#           'output_tipo_cifra': 0.1, # Peso menor para a tarefa mais simples\n",
        "#           'output_decodificacao': 0.9 # Peso maior para a criptoanálise (tarefa mais difícil)\n",
        "#   },\n",
        "#   metrics={\n",
        "#       'output_tipo_cifra': 'accuracy',\n",
        "#       'output_decodificacao': 'accuracy'\n",
        "#   }\n",
        "# )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V-LbuxfHENxu"
      },
      "source": [
        "#### **Justificativa para o Otimizador Adam**\n",
        "\n",
        "#### O otimizador **Adam** (*Adaptive Moment Estimation*) foi escolhido por ser o algoritmo de otimização mais eficiente e confiável para modelos de Deep Learning baseados em sequências (RNNs, LSTMs e GRUs). Ele supera métodos mais simples, como o SGD (*Stochastic Gradient Descent*), de forma significativa.\n",
        "\n",
        "#### A sua superioridade baseia-se em dois princípios adaptativos:\n",
        "\n",
        "1. #### Taxa de Aprendizado Adaptativa\n",
        "\n",
        "    * Ao contrário do SGD, que utiliza uma única taxa de aprendizado (global) para todos os pesos do modelo, o **Adam** calcula uma **taxa de aprendizado individual** para *cada peso* da rede neural.\n",
        "\n",
        "    * #### **Momentum (Momento):** O Adam utiliza médias móveis de gradientes passados para acelerar a convergência em direções relevantes.\n",
        "    * #### **Adaptação RMSprop:** O Adam também incorpora o conceito do RMSprop, que ajusta a taxa de aprendizado individualmente, o que é crucial para dados sequenciais onde o \"terreno\" da função de perda é irregular.\n",
        "\n",
        "2. #### Estabilidade e Eficiência\n",
        "\n",
        "* #### Para o seu modelo **Multi-Task Encoder-Decoder**, o Adam oferece as seguintes vantagens práticas:\n",
        "\n",
        "  * #### **Convergência Mais Rápida:** O Adam geralmente atinge o ponto de convergência (o mínimo da função de perda) muito mais rápido que outros otimizadores.\n",
        "  * #### **Estabilidade:** Ele requer menos ajuste fino dos hiperparâmetros (como a taxa de aprendizado) do que outros métodos, tornando o experimento mais estável e eficiente.\n",
        "\n",
        "#### Portanto, o **Adam** é a escolha ideal para treinar uma arquitetura complexa como a sua, garantindo um ajuste de peso eficiente nas camadas Embedding e LSTM."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 137,
      "metadata": {
        "id": "H-B218_1CR2M"
      },
      "outputs": [],
      "source": [
        "# modelo.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XwOjFtyRDSXX"
      },
      "source": [
        "### **Análise do `model.summary()` (Validação da Arquitetura)**\n",
        "\n",
        "#### O resumo da arquitetura Keras confirma que o modelo **Multi-Task Encoder-Decoder** foi construído com sucesso e que as correções críticas (como o uso da camada `Embedding` e as dimensões de saída) estão aplicadas corretamente.\n",
        "\n",
        "#### 1. Validação Estrutural e Dimensionalidade\n",
        "\n",
        "#### O resumo comprova o alinhamento total das dimensões com os dados que você preparou:\n",
        "\n",
        "| Componente | Output Shape | Confirmação |\n",
        "| :--- | :--- | :--- |\n",
        "| **`MAX_SEQ_LEN`** | `(None, 515)` | O comprimento máximo de sequência está corretamente padronizado para **515 *tokens*** em todos os *Inputs* e *Outputs*. |\n",
        "| **`VOCAB_SIZE`** | `37` | O *Output* de Decodificação tem **37 saídas** (o tamanho exato do seu vocabulário), provando que a rede está predizendo corretamente a probabilidade de cada *token* a cada passo de tempo. |\n",
        "| **`LATENT_DIM`** | `256` | O espaço latente (a memória do Encoder/Decoder) está definido em 256 unidades, como planejado. |\n",
        "| **Camadas Embedding** | `(None, 515, 128)` | Ambas as camadas (`encoder_embedding` e `decoder_embedding`) estão presentes, confirmando que o modelo aceita **IDs Inteiros** (o formato correto) e os transforma em vetores densos de 128 dimensões. |\n",
        "\n",
        "#### 2. Validação das Heads (Saídas Multi-Task)\n",
        "\n",
        "#### O resumo prova que a rede possui as duas saídas necessárias para a compilação:\n",
        "\n",
        "| Head (Saída) | Layer Name | Output Shape | Status |\n",
        "| :--- | :--- | :--- | :--- |\n",
        "| **Decodificação** | `output_decodificacao` | `(None, 515, 37)` | **Correto.** Previsão de sequência alinhada com o `MAX_SEQ_LEN` e o `VOCAB_SIZE`. |\n",
        "| **Classificação** | `output_tipo_cifra` | `(None, 2)` | **Correto.** Predição binária (César ou Vigenère), pronta para o Target **One-Hot Encoded**. |\n",
        "\n",
        "---\n",
        "\n",
        "#### **Conclusão:** O modelo está totalmente definido e pronto para ser treinado com os seus nove arrays NumPy, utilizando as funções de perda e pesos definidos na compilação (`sparse_categorical_crossentropy` e `categorical_crossentropy`)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CBHOw7NDJeK8"
      },
      "source": [
        "## A.3. **Treinamento e Estratégia de Combate ao Overfitting**\n",
        "### Essa é a etapa em que demonstramos nossa estratégia para lidar com o **overfitting** e garantir que os pesos da arquitetura complexa sejam ajustados de forma eficiente.\n",
        "\n",
        "### O modelo será treinado usando o otimizador **Adam** e alimentado com os *tensors* do conjunto de Treinamento (70%).\n",
        "\n",
        "### A complexidade da arquitetura **Multi-Task Encoder-Decoder** exige a implementação de **mecanismos de controle** para garantir a estabilidade e a generalização do aprendizado:\n",
        "\n",
        "1. ### **Teacher Forcing (Input do Decoder)**\n",
        "\n",
        "    * #### Durante o treinamento, o Decoder é alimentado com o Target de Decodificação (`Y_decodificacao_treino`) como seu próprio *input*. Esta técnica, conhecida como **Teacher Forcing**, acelera significativamente a convergência e o aprendizado, pois o modelo recebe a \"resposta correta\" no passo anterior, corrigindo o caminho do treinamento.\n",
        "\n",
        "2. ### **Callbacks Essenciais (Controle de Generalização)**\n",
        "\n",
        "    * #### Para combater o principal risco em Deep Learning, o **Overfitting**, implementamos duas *callbacks* essenciais monitorando o desempenho no conjunto de Validação (10%):\n",
        "\n",
        "      * #### **Early Stopping:** Monitora a **perda na Validação (`val_loss`)** e interrompe o treinamento se não houver melhora após um número definido de épocas (`patience`). Esta *callback* é crucial para garantir que a rede neural **pare de memorizar** os dados de treino e restaure os pesos do ponto onde a generalização foi ideal.\n",
        "      * #### **Model Checkpoint:** Salva automaticamente os pesos da rede na época em que o desempenho no conjunto de Validação foi o melhor.\n",
        "\n",
        "### Essa estratégia garante que o treinamento seja focado na convergência das perdas, ao mesmo tempo que maximiza a capacidade do modelo de aplicar a criptoanálise em dados totalmente inéditos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 138,
      "metadata": {
        "id": "Lzwj0VNpLDUQ"
      },
      "outputs": [],
      "source": [
        "# DEFINIÇÃO DOS CALLBACKS\n",
        "\n",
        "# Early Stopping: Impede o Overfitting\n",
        "# Monitoramos a perda (loss) da VALIDAÇÃO, pois é a métrica mais honesta\n",
        "# early_stopping = EarlyStopping(\n",
        "#     monitor='val_loss', # Mética a ser monitorada (perda total na validação)\n",
        "#     patience=15,          # Número de épocas sem melhora antes de parar\n",
        "#     verbose=1,\n",
        "#     restore_best_weights=True # Restarua os pesos do modelo que teve a melhor performance\n",
        "# )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 139,
      "metadata": {
        "id": "TxeejAZXLvMU"
      },
      "outputs": [],
      "source": [
        "# Model Checkpoint: Salva o melhor modelo\n",
        "# checkpoint = ModelCheckpoint(\n",
        "#     '/content/biblia-cifra-cesar-vigenere/melhor_modelo_cripto.keras',\n",
        "#     monitor='val_loss',\n",
        "#     save_best_only=True,\n",
        "#     verbose=1\n",
        "# )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 140,
      "metadata": {
        "id": "86m6gmuoMDh_"
      },
      "outputs": [],
      "source": [
        "# callbacks_list = [early_stopping, checkpoint]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rXt8EW8QNTfN"
      },
      "source": [
        "### Agora, vamos para a execução do modelo!\n",
        "### O tempo de treinamento total do modelo foi monitorado usando o módulo time do Python, registrando *[X minutos e Y segundos]* até que o *Early Stopping* fosse acionado, garantindo a otimização de recursos e tempo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 141,
      "metadata": {
        "id": "DfXzlkEmaeyD"
      },
      "outputs": [],
      "source": [
        "# Define a variável de ambiente para forçar o log das GPUs\n",
        "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
        "\n",
        "# --- VERIFICAÇÃO CRÍTICA DE HARDWARE ---\n",
        "# dispositivos_gpu = tf.config.list_physical_devices('GPU')\n",
        "\n",
        "# if not dispositivos_gpu:\n",
        "#     print(\"--------------------------------------------------------------------------------------------------------------------------------\")\n",
        "#     print(\"ERRO DE EXECUÇÃO: ACELERADOR DE HARDWARE NECESSÁRIO.\")\n",
        "#     print(\"O modelo Encoder-Decoder exige GPU ou TPU para processamento eficiente.\")\n",
        "#     print(\"POR FAVOR, ATIVE A GPU OU TPU: Menu 'Ambiente de Execução' -> 'Alterar tipo de ambiente de execução' -> Selecione 'GPU' ou 'TPU'.\")\n",
        "#     print(\"--------------------------------------------------------------------------------------------------------------------------------\")\n",
        "#     raise RuntimeError(\"TREINAMENTO CANCELADO. POR FAVOR, ATIVAR O ACELERADOR DE HARDWARE (GPU ou TPU).\")\n",
        "# else:\n",
        "# print(f\"Acelerador detectado ({dispositivos_gpu[0].device_type}). Iniciando treinamento com BATCH_SIZE={BATCH_SIZE}...\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 142,
      "metadata": {
        "id": "rnD-McciNiUj"
      },
      "outputs": [],
      "source": [
        "# EXECUÇÃO DO TREINAMENTO\n",
        "\n",
        "# print(\"Iniciando treinamento do modelo Multi-Task...\")\n",
        "\n",
        "# 1. Registrar o tempo de início\n",
        "# inicio_treinamento = time.time()\n",
        "\n",
        "# history = modelo.fit(\n",
        "#     x=[X_treino, Y_decodificacao_treino],\n",
        "#     y={\n",
        "#       'output_tipo_cifra': Y_classificacao_treino,\n",
        "#       'output_decodificacao': Y_decodificacao_treino\n",
        "#     },\n",
        "#     epochs=100, # Deixamos um número alto, mas o EarlyStopping fará a parada\n",
        "#     batch_size=BATCH_SIZE,\n",
        "\n",
        "#     # Dados de validação: Estrutura idêntica à do treinamento\n",
        "#     validation_data=(\n",
        "#         [X_val, Y_decodificacao_val], # Inputs de validação\n",
        "#         {\n",
        "#           'output_tipo_cifra': Y_classificacao_val,\n",
        "#           'output_decodificacao': Y_decodificacao_val\n",
        "#         } # Targets de validação\n",
        "#     ),\n",
        "#     callbacks=callbacks_list,\n",
        "#     verbose=1\n",
        "# )\n",
        "\n",
        "# # 2. Registrar o tempo de término\n",
        "# fim_treinamento = time.time()\n",
        "\n",
        "# # 3. Calcular e formatar o tempo total\n",
        "# tempo_total_segundos = fim_treinamento - inicio_treinamento\n",
        "\n",
        "# # Converte o tempo total para um formato legível (minutos e segundos)\n",
        "# minutos = int(tempo_total_segundos // 60)\n",
        "# segundos = int(tempo_total_segundos % 60)\n",
        "\n",
        "# print(f\"\\nTreinamento concluído. O melhor modelo foi salvo.\")\n",
        "# print(f\"Tempo total de treinamento: {minutos} minutos e {segundos} segundos.\")\n",
        "\n",
        "# # Guarde a variável para usar no cabeçalho do projeto, se necessário\n",
        "# tempo_final_formatado = f\"{minutos}m {segundos}s\"\n",
        "\n",
        "# modelo.save('/content/biblia-cifra-cesar-vigenere/melhor_modelo_cripto_treinado.keras')\n",
        "# print(\"\\nModelo treinado e os melhores pesos salvos em 'melhor_modelo_cripto_treinado.keras'.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HQ23wA5nQuiG"
      },
      "source": [
        "#### A primeira vez que executei esse código, ele simplesmente travou o ambiente do Colab por consumir toda a memória, há uma suspeita de uma falha de baixo nível, geralmente relacionada à ***incompatibilidade de shapes (dimensões)*** ou ***exaustão de memória (OOM)** no ambiente Colab. O treinamento sequer começou.\n",
        "\n",
        "#### Isso é uma falha crítica que o *TensorFlow/Keras* não consegue diagnosticar antes de travar o kernel.\n",
        "\n",
        "#### O problema mais provável é que uma das suas três matrizes de treinamento não esteja no formato exato que a arquitetura Multi-Task espera.\n",
        "#### Vamos verificar o que aconteceu executando um código simples de diagnóstico"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 143,
      "metadata": {
        "id": "gAaxUuEwRW-Q"
      },
      "outputs": [],
      "source": [
        "# import numpy as np\n",
        "\n",
        "# print(\"--- Diagnóstico dos Arrays de Treinamento ---\")\n",
        "# print(f\"Número de Amostras de Treino: {len(X_treino)}\")\n",
        "# print(\"-\" * 40)\n",
        "\n",
        "# Input do Encoder (X)\n",
        "# print(f\"X_treino (Cifrado): Shape={X_treino.shape}, Dtype={X_treino.dtype}\")\n",
        "\n",
        "# Input do Decoder E Target de Decodificação (Y_decodificacao)\n",
        "# Ambas as cabeças precisam ser idênticas: (num_amostras, MAX_SEQ_LEN)\n",
        "# print(f\"Y_decodificacao_treino: Shape={Y_decodificacao_treino.shape}, Dtype={Y_decodificacao_treino.dtype}\")\n",
        "\n",
        "# Target de Classificação (Y_classificacao)\n",
        "# Formato One-Hot: (num_amostras, 2)\n",
        "# print(f\"Y_classificacao_treino: Shape={Y_classificacao_treino.shape}, Dtype={Y_classificacao_treino.dtype}\")\n",
        "# print(\"-\" * 40)\n",
        "\n",
        "# Verificação Crítica: Tipos de Dados\n",
        "# if X_treino.dtype != np.dtype('int32') or Y_decodificacao_treino.dtype != np.dtype('int32'):\n",
        "#     print(\"ALERTA: Os arrays sequenciais devem ser de tipo INT32.\")\n",
        "# if Y_classificacao_treino.dtype != np.dtype('float32'):\n",
        "#     print(\"ALERTA: O array de classificação deve ser de tipo FLOAT32 (Devido ao One-Hot).\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "5M2H34c8yoWH",
        "fciZeWbDyvLJ",
        "cggNCEEhzDSb",
        "NeRrXOO8zLaC"
      ],
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMa4zTCLBb5X9m8I6hlAnFC",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}